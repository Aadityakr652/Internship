{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e84158",
   "metadata": {},
   "source": [
    "## Assignment - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c65f4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries \n",
    "import selenium\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import InvalidArgumentException\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "# Setting up the WebDriver options in order to use brave\n",
    "brave_path=r'C:\\Program Files\\BraveSoftware\\Brave-Browser\\Application\\brave.exe'\n",
    "options=wd.ChromeOptions()\n",
    "options.binary_location=brave_path\n",
    "driver_path=r'D:\\Files\\chromedriver.exe' \n",
    "options.add_argument(\"--incognito\")  # Opening browser in incognito mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649f932",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90d4ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the driver\n",
    "dr=wd.Chrome(executable_path=driver_path, options=options)\n",
    "#Opening the website on automated brave browser\n",
    "dr.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5570358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the required data\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5d76c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the required data\n",
    "shift=0#Initilizing the variable\n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//div[@class=\"vector-body ve-init-mw-desktopArticleTarget-targetContainer\"]/div[3]/div/table[2]/tbody/tr/td'):        \n",
    "        shift+=1#Assigning and increasing the value by 1 itself\n",
    "        \n",
    "        #Using if and elif to append values to their respective variables\n",
    "        if shift==1:\n",
    "           \n",
    "            try:#Handling exceptions \n",
    "                Rank.append(i.text.split('.')[0])#Appending rank\n",
    "            except NoSuchElementException:\n",
    "                Rank.append('-')#Appending '-' if  element is not found\n",
    "        \n",
    "        elif shift==2:\n",
    "            \n",
    "            try:#Handling exceptions\n",
    "                Name.append(i.text)#Appending name\n",
    "            except NoSuchElementException:\n",
    "                Name.append('-')#Appending '-' if element is not found\n",
    "        \n",
    "        elif shift==3:\n",
    "           \n",
    "            try:#Handling exceptions\n",
    "                Artist.append(i.text)#Appending artist\n",
    "            except NoSuchElementException:\n",
    "                Artist.append('-')#Appending '-' if  element is not found\n",
    "        \n",
    "        elif shift==4:\n",
    "          \n",
    "            try:#Handling exceptions\n",
    "                Views.append(i.text)#Appending views\n",
    "            except NoSuchElementException:\n",
    "                Views.append('-')#Appending '-' if  element is not found\n",
    "        \n",
    "        elif shift==5:\n",
    "        \n",
    "            try:#Handling exceptions\n",
    "                Upload_date.append(i.text)#Appending upload date\n",
    "            except NoSuchElementException:\n",
    "                Upload_date.append('-')#Appending '-' if  element is not found\n",
    "                \n",
    "        elif shift==6:\n",
    "            shift=0\n",
    "except NoSuchElementException:\n",
    "    print(\"Exception raised...\\nUnable to locate table\")#Printing exception if table is not found\n",
    "dr.close() #Closing the automated  browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e6ddb21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank:-\n",
      "len: 30 \n",
      "Data:\n",
      " ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30'] \n",
      "\n",
      " Name:-\n",
      "len: 30 \n",
      "Data:\n",
      " ['\"Baby Shark Dance\"[4]', '\"Despacito\"[7]', '\"Johny Johny Yes Papa\"[14]', '\"Bath Song\"[15]', '\"Shape of You\"[16]', '\"See You Again\"[19]', '\"Phonics Song with Two Words\"[24]', '\"Wheels on the Bus\"[25]', '\"Uptown Funk\"[26]', '\"Learning Colors – Colorful Eggs on a Farm\"[27]', '\"Gangnam Style\"[28]', '\"Masha and the Bear – Recipe for Disaster\"[33]', '\"Dame Tu Cosita\"[34]', '\"Axel F\"[35]', '\"Sugar\"[36]', '\"Roar\"[37]', '\"Counting Stars\"[38]', '\"Sorry\"[39]', '\"Baa Baa Black Sheep\"[40]', '\"Thinking Out Loud\"[41]', '\"Waka Waka (This Time for Africa)\"[42]', '\"Dark Horse\"[43]', '\"Lakdi Ki Kathi\"[44]', '\"Faded\"[45]', '\"Perfect\"[46]', '\"Let Her Go\"[47]', '\"Girls Like You\"[48]', '\"Humpty the train on a fruits ride\"[49]', '\"Lean On\"[50]', '\"Bailando\"[51]'] \n",
      "\n",
      " Artist:-\n",
      "len: 30 \n",
      "Data:\n",
      " [\"Pinkfong Baby Shark - Kids' Songs & Stories\", 'Luis Fonsi', 'LooLoo Kids', 'Cocomelon – Nursery Rhymes', 'Ed Sheeran', 'Wiz Khalifa', 'ChuChu TV', 'Cocomelon – Nursery Rhymes', 'Mark Ronson', 'Miroshka TV', 'Psy', 'Get Movies', 'El Chombo', 'Crazy Frog', 'Maroon 5', 'Katy Perry', 'OneRepublic', 'Justin Bieber', 'Cocomelon – Nursery Rhymes', 'Ed Sheeran', 'Shakira', 'Katy Perry', 'Jingle Toons', 'Alan Walker', 'Ed Sheeran', 'Passenger', 'Maroon 5', 'Kiddiestv Hindi – Nursery Rhymes & Kids Songs', 'Major Lazer', 'Enrique Iglesias'] \n",
      "\n",
      " Views:-\n",
      "len: 30 \n",
      "Data:\n",
      " ['12.85', '8.16', '6.70', '6.20', '6.00', '5.89', '5.30', '5.24', '4.92', '4.89', '4.80', '4.55', '4.35', '3.91', '3.87', '3.80', '3.79', '3.66', '3.64', '3.60', '3.59', '3.52', '3.48', '3.45', '3.45', '3.44', '3.42', '3.41', '3.38', '3.38'] \n",
      "\n",
      " Upload Date:-\n",
      "len: 30 \n",
      "Data:\n",
      " ['June 17, 2016', 'January 12, 2017', 'October 8, 2016', 'May 2, 2018', 'January 30, 2017', 'April 6, 2015', 'March 6, 2014', 'May 24, 2018', 'November 19, 2014', 'February 27, 2018', 'July 15, 2012', 'January 31, 2012', 'April 5, 2018', 'June 16, 2009', 'January 14, 2015', 'September 5, 2013', 'May 31, 2013', 'October 22, 2015', 'June 25, 2018', 'October 7, 2014', 'June 4, 2010', 'February 20, 2014', 'June 14, 2018', 'December 3, 2015', 'November 9, 2017', 'July 25, 2012', 'May 31, 2018', 'January 26, 2018', 'March 22, 2015', 'April 11, 2014'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing Data along with their length\n",
    "print('Rank:-\\nlen:',len(Rank),'\\nData:\\n',Rank,'\\n\\n','Name:-\\nlen:',len(Name),'\\nData:\\n',Name,'\\n\\n','Artist:-\\nlen:',len(Artist),'\\nData:\\n',Artist,'\\n\\n','Views:-\\nlen:',len(Views),'\\nData:\\n',Views,'\\n\\n','Upload Date:-\\nlen:',len(Upload_date),'\\nData:\\n',Upload_date,'\\n\\n',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38f24b",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "384b149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the driver\n",
    "dr=wd.Chrome(executable_path=driver_path, options=options)\n",
    "#Opening the website on automated brave browser\n",
    "dr.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8f83ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the International tab\n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a').click()\n",
    "except ElementNotInteractableException:\n",
    "    print('Exception Raised...Unable to interact with the element')#Printing exception if element is not interactable\n",
    "except NoSuchElementException:\n",
    "    print(\"Exception raised...\\nUnable to locate the element\")#Printing exception if  element is not  found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c00c7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying filters\n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[1]').click()#Clicking on the ALL FORMATS option\n",
    "except ElementNotInteractableException:\n",
    "    print('Exception Raised...Unable to interact with All FORMATS tab')#Printing exception if element is not interactable\n",
    "except NoSuchElementException:\n",
    "    print(\"Exception raised...\\nUnable to locate All FORMATS tab\")#Printing exception if element is not found\n",
    "    \n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[2]/div[3]').click()#Clicking on the ODI option\n",
    "except ElementNotInteractableException:\n",
    "    print('Exception Raised...Unable to interact with ODI tab')#Printing exception if element is not interactable\n",
    "except NoSuchElementException:\n",
    "    print(\"Exception raised...\\nUnable to locate ODI tab\")#Printing exception if  element is not found\n",
    "\n",
    "#Adding delay to allow the website to load and update the content\n",
    "time.sleep(3)\n",
    "\n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[4]/div/div[1]').click()#Clicking on the ALL TEAMS option\n",
    "except ElementNotInteractableException:\n",
    "    print('Exception Raised...Unable to interact with ALL TEAMS tab')#Printing exception if element is not interactable\n",
    "except NoSuchElementException:\n",
    "    print(\"Exception raised...\\nUnable to locate ALL TEAMS tab\")#Printing exception if  element is not found \n",
    "    \n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[4]/div/div[2]/div[3]').click()#Clicking on the India option\n",
    "except ElementNotInteractableException:\n",
    "    print('Exception Raised...Unable to interact with India tab')#Printing exception if element is not interactable\n",
    "except NoSuchElementException:\n",
    "    print(\"Exception raised...\\nUnable to locate India tab\")#Printing exception if  element is not  found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0eaa94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the required data\n",
    "title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time_=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae8756a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the required data\n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]'):\n",
    "        title.append(i.text.split('-')[0])#Appending title\n",
    "except NoSuchElementException:\n",
    "    title.append('-')#Appending '-' if title is not found\n",
    "\n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]'):\n",
    "        series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    series.append('-')#Appending '-' if series is not found\n",
    "    \n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "        date.append(i.text)#Appending date\n",
    "except NoSuchElementException:\n",
    "    date.append('-')#Appending '-' if date is not found\n",
    "    \n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "        time_.append(i.text)#Appending time\n",
    "except NoSuchElementException:\n",
    "    time_.append('-')#Appending '-' if time is not found\n",
    "    \n",
    "try:#handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]'):\n",
    "        place.append(i.text.split('-',)[1])#Appending place\n",
    "except NoSuchElementException:\n",
    "            place.append('-')#Appending '-' if place is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4675f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:-\n",
      "len: 3 \n",
      "Data:\n",
      " ['1st ODI ', '2nd ODI ', '3rd ODI '] \n",
      "\n",
      " Series:-\n",
      "len: 3 \n",
      "Data:\n",
      " ['INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023'] \n",
      "\n",
      " Place:-\n",
      "len: 3 \n",
      "Data:\n",
      " [' Kensington Oval, Barbados', ' Kensington Oval, Barbados', ' Brian Lara Stadium, Trinidad'] \n",
      "\n",
      " Date:-\n",
      "len: 3 \n",
      "Data:\n",
      " ['27 JUL 2023', '29 JUL 2023', '1 AUG 2023'] \n",
      "\n",
      " Time:-\n",
      "len: 3 \n",
      "Data:\n",
      " ['7:00 PM IST', '7:00 PM IST', '7:00 PM IST'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing Data along with their length\n",
    "print('Title:-\\nlen:',len(title),'\\nData:\\n',title,'\\n\\n','Series:-\\nlen:',len(series),'\\nData:\\n',series,'\\n\\n','Place:-\\nlen:',len(place),'\\nData:\\n',place,'\\n\\n','Date:-\\nlen:',len(date),'\\nData:\\n',date,'\\n\\n','Time:-\\nlen:',len(time_),'\\nData:\\n',time_,'\\n\\n',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6c795",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8204539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the driver\n",
    "dr=wd.Chrome(executable_path=driver_path, options=options)\n",
    "#Opening the website on automated brave browser\n",
    "dr.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45da3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the url of India's economy tab\n",
    "try:#Handling exceptions\n",
    "    tab=dr.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/div/a[3]')\n",
    "    tab=tab.get_attribute('href')\n",
    "    #Opening the new tab on automated brave browser\n",
    "    dr.get(tab)\n",
    "except NoSuchElementException:\n",
    "    print(\"Exception raised...\\nUnable to locate tab\")#Printing exception if element is not found\n",
    "except InvalidArgumentException:\n",
    "    print('Exception Raised...Invalid argument')#Printing exception in case of invalid argument  \n",
    "except TimeoutException:\n",
    "    print('Exception Raised...Time out occured')#Printing exception if it encounters timeout error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee39f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the GDP of Indian states tab\n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "except NoSuchElementException:\n",
    "    print(\"Exception raised...\\nUnable to locate tab\")#Printing exception if element is not found\n",
    "except ElementNotInteractableException :\n",
    "    print(\"Exception raised...\\nUnable to interact with the element\")#Printing exception if code is unable to interact with the element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63f3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the required data\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_18_19_ACP=[]\n",
    "GSDP_19_20_ACP=[]\n",
    "Share=[] \n",
    "GDP=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e83aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the required data\n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//td[@class=\"data1\"]')[0:33]:#Using slicing to scrape the required data\n",
    "        Rank.append(i.text)#Appending Ranks\n",
    "except NoSuchElementException:\n",
    "    Rank.append('-')#Appending '-' if element is not found\n",
    "    \n",
    "\n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//td[@class=\"name\"]')[0:33]:#Using slicing to scrape the required data\n",
    "        State.append(i.text)#Appending States\n",
    "except NoSuchElementException:\n",
    "    State.append('-')#Appending '-' if  element is not found\n",
    "\n",
    "\n",
    "try:#Handling exceptions\n",
    "    shift=0#Initlizing the variable\n",
    "    for i in dr.find_elements(By.XPATH,'//td[@class=\"data\"]')[0:165]:#Using slicing to scrape the required data\n",
    "        shift+=1#Assigning and increasing the value by 1 itself\n",
    "        \n",
    "        if shift==1:\n",
    "            try:#Handling exceptions\n",
    "                GSDP_19_20_ACP.append(i.text)#Appending GSDP(19-20)- at current prices\n",
    "            except NoSuchElementException:\n",
    "                GSDP_19_20_ACP.append('-')#Appending '-' if  element is not found\n",
    "                \n",
    "        if shift==2:\n",
    "            try:#Handling exceptions\n",
    "                Share.append(i.text)#Appending Shares\n",
    "            except NoSuchElementException:\n",
    "                Share.append('-')#Appending '-' if element is not found\n",
    "                \n",
    "        if shift==3:\n",
    "            try:#Handling exceptions\n",
    "                GDP.append(i.text)#Appending GDP\n",
    "            except NoSuchElementException:\n",
    "                GDP.append('-')#Appending '-' if  element is not found\n",
    "        \n",
    "        if shift==4:\n",
    "            continue\n",
    "        \n",
    "        if shift==5:\n",
    "            shift=0\n",
    "            continue\n",
    "            \n",
    "                               \n",
    "except NoSuchElementException:\n",
    "    print(\"Exception raised...\\nUnable to locate the element\")#Printing exception if  element is not found\n",
    "    \n",
    "\n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//td[@class=\"data1\"]')[0:33]:#Using slicing to scrape the required data\n",
    "        GSDP_18_19_ACP.append(i.text)#Appending GSDP(18-19)- at current prices\n",
    "except NoSuchElementException:\n",
    "    GSDP_18_19_ACP.append('-')#Appending '-' if element is not found   \n",
    "dr.close() #Closing the automated  browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56bd69e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank:-\n",
      "len: 33 \n",
      "Data:\n",
      " ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33'] \n",
      "\n",
      " States:-\n",
      "len: 33 \n",
      "Data:\n",
      " ['Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Gujarat', 'Karnataka', 'West Bengal', 'Rajasthan', 'Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Sikkim', 'Manipur', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands'] \n",
      "\n",
      " GSDP 19-20 ACP:-\n",
      "len: 33 \n",
      "Data:\n",
      " ['-', '1,845,853', '1,687,818', '-', '1,631,977', '1,253,832', '1,020,989', '972,782', '969,604', '906,672', '-', '856,112', '831,610', '611,804', '574,760', '521,275', '-', '329,180', '328,598', '-', '-', '165,472', '80,449', '55,984', '-', '38,253', '36,572', '32,496', '31,790', '-', '-', '26,503', '-'] \n",
      "\n",
      "  Share(18-19):-\n",
      "len: 33 \n",
      "Data:\n",
      " ['13.94%', '8.63%', '8.39%', '7.96%', '7.91%', '5.77%', '4.99%', '4.57%', '4.56%', '4.29%', '4.14%', '4.10%', '3.89%', '2.81%', '2.79%', '2.58%', '1.67%', '1.61%', '1.57%', '1.30%', '0.83%', '0.81%', '0.39%', '0.26%', '0.22%', '0.18%', '0.18%', '0.15%', '0.15%', '0.14%', '0.13%', '0.12%', '-'] \n",
      "\n",
      " GDP($ billion):-\n",
      "len: 33 \n",
      "Data:\n",
      " ['399.921', '247.629', '240.726', '228.290', '226.806', '165.556', '143.179', '131.083', '130.791', '122.977', '118.733', '117.703', '111.519', '80.562', '79.957', '74.098', '47.982', '46.187', '45.145', '37.351', '23.690', '23.369', '11.115', '7.571', '6.397', '5.230', '5.086', '4.363', '4.233', '4.144', '3.737', '3.385', '-'] \n",
      "\n",
      " GSDP 18-19 ACP:-\n",
      "len: 33 \n",
      "Data:\n",
      " ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing Data along with their length\n",
    "print('Rank:-\\nlen:',len(Rank),'\\nData:\\n',Rank,'\\n\\n','States:-\\nlen:',len(State),'\\nData:\\n',State,'\\n\\n','GSDP 19-20 ACP:-\\nlen:',len(GSDP_19_20_ACP),'\\nData:\\n',GSDP_19_20_ACP,'\\n\\n',' Share(18-19):-\\nlen:',len(Share),'\\nData:\\n',Share,'\\n\\n','GDP($ billion):-\\nlen:',len(GDP),'\\nData:\\n',GDP,'\\n\\n','GSDP 18-19 ACP:-\\nlen:',len(GSDP_18_19_ACP),'\\nData:\\n',GSDP_18_19_ACP,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8782c8",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d6a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the driver\n",
    "dr=wd.Chrome(executable_path=driver_path, options=options)\n",
    "#Opening the website on automated brave browser\n",
    "dr.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a6f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching link of the trending tab \n",
    "try:#Handling exceptions\n",
    "    tab=dr.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "    tab=tab.get_attribute('href')\n",
    "    dr.get(tab)\n",
    "except InvalidArgumentException:\n",
    "    print('Exception Raised...Invalid argument')#Printing exception in case of invalid argument\n",
    "except NoSuchElementException:\n",
    "    print('Exception Raised...Unable to locate tab') #Printing exception if tab is not interactable\n",
    "except TimeoutException:\n",
    "    print('Exception Raised...Time out occured')#Printing exception if it encounters timeout error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed92e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the required data\n",
    "r_title=[]\n",
    "r_description=[]\n",
    "count=[]\n",
    "language=[]\n",
    "r_url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20fc9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping URLs of the repositories\n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a'):\n",
    "        r_url.append(i.get_attribute('href'))\n",
    "except NoSuchElementException:\n",
    "    print('Exception Raised...Unable to locate url of the repository') #Printing exception if  URL is not found\n",
    "\n",
    "try:#Handling exceptions\n",
    "    #Scraping titles of the repositories\n",
    "    for i in dr.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]'):\n",
    "        r_title.append(i.text)#Appending titles\n",
    "except NoSuchElementException:\n",
    "    print('Exception Raised...Unable to locate url of the repository') #Printing exception if title is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad5ebaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating URLs\n",
    "try:#Handling exceptions\n",
    "    for i in r_url:\n",
    "        dr.get(i)\n",
    "        \n",
    "        try:#Handling exceptions\n",
    "            r_description.append(dr.find_element(By.XPATH,'//p[@class=\"f4 my-3\"]').text)#Appending description\n",
    "        except NoSuchElementException:\n",
    "            r_description.append('-')#Appending '-' if  description is not found\n",
    "        \n",
    "        try:#Handling exceptions\n",
    "            count.append(dr.find_element(By.XPATH,'//div[@class=\"BorderGrid BorderGrid--spacious\"]/div[6]/div/h2/a/span').text)#Appending Contributors count\n",
    "        except NoSuchElementException:\n",
    "            count.append('-')#Appending '-' if  Contributors count is not found\n",
    "            \n",
    "        try:#Handling exceptions\n",
    "            language.append(dr.find_element(By.XPATH,'//a[@class=\"d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline text-small mr-3\"]/span').text)#Appending languages\n",
    "        except NoSuchElementException:\n",
    "            language.append('-')#Appending '-' if  language is not found    \n",
    "        \n",
    "        #Adding delay to allow the website to load and update the content\n",
    "        time.sleep(3)\n",
    "\n",
    "except InvalidArgumentException:\n",
    "    print('Exception Raised...Invalid argument')#Printing exception in case of invalid argument    \n",
    "except TimeoutException:\n",
    "    print('Exception Raised...Time out occured')#Printing exception if it encounters timeout error\n",
    "dr.close() #Closing the automated  browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50ef359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository title:-\n",
      "len: 25 \n",
      "Data:\n",
      " ['sveltejs / svelte', 'a16z-infra / ai-getting-started', 'vllm-project / vllm', 'figma / plugin-samples', 'google / googletest', 'OpenDriveLab / UniAD', 'csunny / DB-GPT', 's0md3v / sd-webui-roop', 'devfullcycle / imersao13', 'codecrafters-io / build-your-own-x', 'Jessecar96 / SteamDesktopAuthenticator', 'ossu / computer-science', 'TodePond / DreamBerd', 'SkalskiP / top-cvpr-2023-papers', 'serverless-stack / sst', 'scikit-learn / scikit-learn', 'angular / angular', 'AUTOMATIC1111 / stable-diffusion-webui', 'eslint / eslint', 'loft-sh / devpod', 'nodejs / node', 'edtechre / pybroker', 'veler / DevToys', 'geohot / tinygrad', 'terraform-aws-modules / terraform-aws-eks'] \n",
      "\n",
      " Repository description:-\n",
      "len: 25 \n",
      "Data:\n",
      " ['Cybernetically enhanced web apps', 'A Javascript AI getting started stack for weekend projects, including image/text models, vector stores, auth, and deployment configs', 'A high-throughput and memory-efficient inference and serving engine for LLMs', '🔌 Sample Figma plugins.', 'GoogleTest - Google Testing and Mocking Framework', '[CVPR 2023 Best Paper] Planning-oriented Autonomous Driving', 'Revolutionizing Database Interactions with Private LLM Technology', 'roop extension for StableDiffusion web-ui', '-', 'Master programming by recreating your favorite technologies from scratch.', \"Desktop implementation of Steam's mobile authenticator app\", '🎓 Path to a free self-taught education in Computer Science!', 'perfect programming language', 'This repository is a curated collection of the most exciting and influential CVPR 2023 papers. 🔥 [Paper + Code]', '💥 SST makes it easy to build full-stack serverless apps.', 'scikit-learn: machine learning in Python', 'The modern web developer’s platform', 'Stable Diffusion web UI', 'Find and fix problems in your JavaScript code.', 'Spin up dev environments in any infra. Dev-environments-as-code like Terraform but for dev environments. Like Codespaces but open-source, client-only and unopinionated: Works with any IDE and lets you use any cloud, kubernetes or just on localhost docker.', 'Node.js JavaScript runtime ✨🐢🚀✨', 'Algorithmic Trading in Python with Machine Learning', 'A Swiss Army knife for developers.', 'You like pytorch? You like micrograd? You love tinygrad! ❤️', 'Terraform module to create an Elastic Kubernetes (EKS) cluster and associated resources 🇺🇦'] \n",
      "\n",
      " Contributors count:-\n",
      "len: 25 \n",
      "Data:\n",
      " ['606', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '2,672', '-', '-', '952', '-', '-', '-', '-', '-', '-'] \n",
      "\n",
      " Language used:-\n",
      "len: 25 \n",
      "Data:\n",
      " ['JavaScript', 'TypeScript', 'Python', 'TypeScript', 'C++', 'Python', 'Python', 'Python', 'TypeScript', '-', 'C#', '-', '-', 'Python', 'TypeScript', 'Python', 'TypeScript', 'Python', 'JavaScript', 'Go', 'JavaScript', 'Python', 'C#', 'Python', 'HCL']\n"
     ]
    }
   ],
   "source": [
    "#Printing Data along with their length\n",
    "print('Repository title:-\\nlen:',len(r_title),'\\nData:\\n',r_title,'\\n\\n','Repository description:-\\nlen:',len(r_description),'\\nData:\\n',r_description,'\\n\\n','Contributors count:-\\nlen:',len(count),'\\nData:\\n',count,'\\n\\n','Language used:-\\nlen:',len(language),'\\nData:\\n',language,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864f880",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b534ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the driver\n",
    "dr=wd.Chrome(executable_path=driver_path, options=options)\n",
    "#Opening the website on automated brave browser\n",
    "dr.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3910ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the charts tab\n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a').click()\n",
    "except NoSuchElementException:\n",
    "    print('Exception Raised...Unable to locate such element')#Raising exception if element is not present\n",
    "except ElementNotInteractableException:\n",
    "    print('Exception Raised...Element is not interactable')#Raising exception if element is not interactable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a3d8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the Billboard Hot 100 tab\n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a').click()\n",
    "except NoSuchElementException:\n",
    "    print('Exception Raised...Unable to locate such element')#Raising exception if element is not present\n",
    "except ElementNotInteractableException:\n",
    "    print('Exception Raised...Element is not interactable')#Raising exception if element is not interactable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67573ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the required data\n",
    "song=[]\n",
    "artist=[]\n",
    "last_week_rank=[]\n",
    "peak_rank=[]\n",
    "weeks_on_board=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "730a1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping 1st data separately\n",
    "try:#Handling exceptions\n",
    "    song.append(dr.find_element(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\"]').text) #Appending song name\n",
    "except NoSuchElementException:\n",
    "    song.append('-')#Appending '-' if song name is not found\n",
    "    \n",
    "try:#Handling exceptions\n",
    "    artist.append(dr.find_element(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]').text)#Appending artist name\n",
    "except NoSuchElementException:\n",
    "    artist.append('-')#Appending '-' if artist name is not found\n",
    "\n",
    "try:#Handling exceptions\n",
    "    last_week_rank.append(dr.find_element(By.XPATH,'//span[@class=\"c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\"]').text)#Appending last week rank\n",
    "except NoSuchElementException:\n",
    "    last_week_rank.append('-')#Appending '-' if last week rank is not found\n",
    "    \n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\"]')[1:2]:#Using slicing method to scrape the required data\n",
    "        peak_rank.append(i.text)#Appending peak rank\n",
    "except NoSuchElementException:\n",
    "    peak_rank.append('-')#Appending '-' if peak rank is not found\n",
    "    \n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\"]')[2:3]: #Using slicing to scrape the required data\n",
    "        weeks_on_board.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    weeks_on_board.append('-')#Appending '-' if week on board is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d10416c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the required data\n",
    "try:\n",
    "    for i in dr.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]'):#Appending songs name\n",
    "        song.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    song.append('-')#Appending '-' if song name is not available\n",
    "    \n",
    "try:\n",
    "    for i in dr.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]'):\n",
    "        artist.append(i.text)#Appending artist name\n",
    "except NoSuchElementException:\n",
    "    artist.append('-')#Appending '-' if artist name is not available\n",
    "\n",
    "shift=0#Initilizing the variable\n",
    "try:\n",
    "    for i in dr.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]'):\n",
    "        shift+=1#Assigning and increasing the value by 1 itself\n",
    "        \n",
    "        #Using if,elif and else to append values to their respective variables\n",
    "        if shift==1:\n",
    "            try:\n",
    "                last_week_rank.append(i.text) #Appending last week rank\n",
    "            except NoSuchElementException:\n",
    "                last_week_rank.append('-')#Appending '-' if last week rank is not available\n",
    "        elif shift==2:\n",
    "            try:\n",
    "                peak_rank.append(i.text) #Appending peak rank\n",
    "            except NoSuchElementException:\n",
    "                peak_rank.append('-')#Appending '-' if peak rank  is not available\n",
    "                \n",
    "        elif shift==3:\n",
    "            try:\n",
    "                weeks_on_board.append(i.text) #Appending weeks on board\n",
    "            except NoSuchElementException:\n",
    "                weeks_on_board.append('-')#Appending '-' if weeks on board is not available\n",
    "                \n",
    "        elif shift==4:\n",
    "            continue\n",
    "            \n",
    "        elif shift==5:\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            shift=0\n",
    "            continue\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    print('Exception Raised...Unable to locate the elements') #Raising exception incase elements are not found\n",
    "dr.close() #Closing the automated  browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2a5d639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist name:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['Morgan Wallen', 'Miley Cyrus', 'Luke Combs', 'Rema & Selena Gomez', 'Lil Durk Featuring J. Cole', 'Toosii', 'SZA', 'Metro Boomin, The Weeknd & 21 Savage', 'Taylor Swift Featuring Ice Spice', 'Eslabon Armado X Peso Pluma', 'Miguel', 'Taylor Swift', 'The Weeknd & Ariana Grande', 'Zach Bryan', 'SZA', 'Yng Lvcas x Peso Pluma', 'Bad Bunny', 'Grupo Frontera X Bad Bunny', 'Jelly Roll', 'Drake', 'Morgan Wallen', 'Morgan Wallen', 'Post Malone', 'Fifty Fifty', 'Bailey Zimmerman', 'Ed Sheeran', 'PinkPantheress & Ice Spice', 'Jordan Davis', 'Latto Featuring Cardi B', 'Morgan Wallen', 'David Guetta & Bebe Rexha', 'Dua Lipa', 'Kali', 'Tyler Hubbard', 'Morgan Wallen', 'Old Dominion', 'Bizarrap & Peso Pluma', 'Megan Moroney', 'Taylor Swift', 'Fuerza Regida', 'Lil Durk Featuring Morgan Wallen', 'Bailey Zimmerman', 'Noah Kahan', 'Chris Brown', 'Coi Leray', 'Metro Boomin, Swae Lee & NAV Featuring A Boogie Wit da Hoodie', 'Metro Boomin, Swae Lee, Lil Wayne & Offset', 'BTS', 'Luke Combs', 'Kane Brown With Katelyn Brown', 'Metro Boomin, A$AP Rocky & Roisee', 'Ice Spice & Nicki Minaj', 'Peso Pluma', 'Metro Boomin & Coi Leray', 'Scotty McCreery', 'David Kushner', 'Peso Pluma X Natanael Cano', 'Peso Pluma', 'Post Malone', 'Doechii Featuring Kodak Black', 'Tyler, The Creator Featuring Kali Uchis', 'Karol G x Shakira', 'Junior H x Peso Pluma', 'Kane Brown', 'Jonas Brothers', 'Justin Moore & Priscilla Block', 'Jon Pardi', 'El Alfa x Peso Pluma', 'Morgan Wallen Featuring ERNEST', 'Coco Jones', 'David Guetta, Anne-Marie & Coi Leray', 'The Weeknd, Playboi Carti & Madonna', 'NLE Choppa', 'Young Nudy Featuring 21 Savage', 'Beyonce Featuring Kendrick Lamar', 'Rod Wave', 'Morgan Wallen', 'DaBaby', 'Becky G & Peso Pluma', 'Libianca', 'Gunna', 'P!nk', 'Yahritza y Su Esencia x Grupo Frontera', 'Taylor Swift', 'Miley Cyrus', 'Sexyy Red & Tay Keith & Nicki Minaj', 'Lil Baby', 'Moneybagg Yo', 'HARDY', 'Kali Uchis', 'Metro Boomin, Travis Scott & Young Thug', 'Metro Boomin, Future & Lil Uzi Vert', 'Baby Keem & Kendrick Lamar', 'Chino Pacas', 'Metro Boomin Featuring Don Toliver & Future', 'Jelly Roll With Lainey Wilson', 'Yandel & Feid', 'Rosalia & Rauw Alejandro', 'Morgan Wallen', 'Metro Boomin & James Blake'] \n",
      "\n",
      " Song name:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['Last Night', 'Flowers', 'Fast Car', 'Calm Down', 'All My Life', 'Favorite Song', 'Kill Bill', \"Creepin'\", 'Karma', 'Ella Baila Sola', 'Sure Thing', 'Anti-Hero', 'Die For You', 'Something In The Orange', 'Snooze', 'La Bebe', 'Where She Goes', 'Un x100to', 'Need A Favor', 'Search & Rescue', 'You Proof', \"Thinkin' Bout Me\", 'Chemical', 'Cupid', 'Rock And A Hard Place', 'Eyes Closed', \"Boy's A Liar, Pt. 2\", 'Next Thing You Know', 'Put It On Da Floor Again', 'Thought You Should Know', \"I'm Good (Blue)\", 'Dance The Night', 'Area Codes', \"Dancin' In The Country\", 'One Thing At A Time', 'Memory Lane', 'Bzrp Music Sessions, Vol. 55', 'Tennessee Orange', 'Cruel Summer', 'TQM', 'Stand By Me', 'Religiously', 'Dial Drunk', 'Under The Influence', 'Players', 'Calling', 'Annihilate', 'Take Two', 'Love You Anyway', 'Thank God', 'Am I Dreaming', 'Princess Diana', 'Bye', 'Self Love', 'It Matters To Her', 'Daylight', 'PRC', 'Por Las Noches', 'Mourning', 'What It Is (Block Boy)', 'See You Again', 'TQG', 'El Azul', 'Bury Me In Georgia', 'Waffle House', 'You, Me, & Whiskey', 'Your Heart Or Mine', 'Plebada', 'Cowgirls', 'ICU', \"Baby Don't Hurt Me\", 'Popular', 'Slut Me Out', 'Peaches & Eggplants', 'America Has A Problem', 'Fight The Feeling', \"Ain't That Some\", 'Shake Sumn', 'Chanel', 'People', 'Bread & Butter', 'Trustfall', 'Fragil', 'Hits Different', 'Jaded', 'Pound Town 2', 'Low Down', 'Ocean Spray', 'Truck Bed', 'Moonlight', 'Trance', 'All The Way Live', 'The Hillbillies', 'El Gordo Trae El Mando', 'Too Many Nights', 'Save Me', 'Yandel 150', 'Beso', 'I Wrote The Book', 'Hummingbird'] \n",
      "\n",
      " Last week rank:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['1', '2', '4', '3', '5', '7', '6', '9', '10', '8', '12', '11', '14', '15', '19', '23', '16', '17', '20', '18', '22', '24', '25', '21', '27', '33', '26', '38', '13', '32', '29', '35', '37', '36', '30', '42', '31', '45', '47', '34', '28', '50', '-', '46', '39', '41', '44', '-', '52', '40', '51', '53', '54', '62', '49', '56', '55', '57', '58', '73', '60', '63', '64', '77', '74', '72', '80', '-', '76', '75', '82', '43', '67', '92', '66', '81', '83', '85', '78', '91', '48', '100', '88', '65', '98', '68', '89', '69', '-', '97', '96', '61', '-', '93', '-', '86', '-', '94', '-', '90'] \n",
      "\n",
      " Peak rank:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['1', '1', '3', '3', '2', '5', '1', '3', '2', '4', '11', '1', '1', '10', '15', '11', '8', '5', '19', '2', '5', '9', '13', '17', '10', '19', '3', '28', '13', '7', '4', '32', '33', '23', '10', '36', '31', '30', '29', '34', '22', '40', '43', '12', '9', '41', '44', '48', '15', '13', '51', '4', '53', '54', '49', '47', '33', '28', '36', '60', '44', '7', '55', '64', '57', '66', '67', '68', '40', '63', '71', '43', '28', '74', '38', '16', '11', '69', '55', '80', '48', '82', '69', '27', '56', '66', '50', '69', '89', '80', '42', '61', '93', '58', '22', '86', '71', '52', '18', '90'] \n",
      "\n",
      " Weeks on board:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['20', '22', '12', '41', '5', '17', '27', '28', '14', '13', '46', '34', '46', '60', '27', '13', '4', '9', '11', '10', '57', '15', '9', '13', '53', '12', '19', '21', '2', '44', '42', '3', '6', '17', '28', '11', '2', '27', '6', '4', '3', '6', '1', '40', '24', '2', '2', '1', '18', '40', '2', '9', '3', '2', '9', '9', '18', '14', '4', '6', '9', '16', '10', '5', '7', '6', '5', '1', '15', '13', '4', '2', '13', '2', '5', '11', '15', '6', '9', '7', '2', '3', '8', '3', '5', '3', '13', '2', '1', '10', '19', '2', '1', '13', '13', '2', '17', '12', '19', '2']\n"
     ]
    }
   ],
   "source": [
    "#Printing Data along with their length\n",
    "print('Artist name:-\\nlen:',len(artist),'\\nData:\\n',artist,'\\n\\n','Song name:-\\nlen:',len(song),'\\nData:\\n',song,'\\n\\n','Last week rank:-\\nlen:',len(last_week_rank),'\\nData:\\n',last_week_rank,'\\n\\n','Peak rank:-\\nlen:',len(peak_rank),'\\nData:\\n',peak_rank,'\\n\\n','Weeks on board:-\\nlen:',len(weeks_on_board),'\\nData:\\n',weeks_on_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd75bb",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6698bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the driver\n",
    "dr=wd.Chrome(executable_path=driver_path, options=options)\n",
    "#Opening the website on automated brave browser\n",
    "dr.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba074774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the required data\n",
    "book_name=[]\n",
    "author_name=[]\n",
    "volumes_sold=[]\n",
    "publisher=[]\n",
    "genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15c20bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the requried data:\n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]'):\n",
    "        book_name.append(i.text)#Appending book name\n",
    "except NoSuchElementException:\n",
    "    book_name.append(i.text)#Appending '-' if book name is not available\n",
    "    \n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]'):\n",
    "        author_name.append(i.text)#Appending author name\n",
    "except NoSuchElementException:\n",
    "    author_name.append(i.text)#Appending '-' if author name is not available\n",
    "    \n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]'):\n",
    "        volumes_sold.append(i.text)#Appending volume sold\n",
    "except NoSuchElementException:\n",
    "    volumes_sold.append(i.text)#Appending '-' if volume sold is not available\n",
    "    \n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]'):\n",
    "        publisher.append(i.text)#Appending publisher \n",
    "except NoSuchElementException:\n",
    "     publisher.append(i.text)#Appending '-' if publisher is not available\n",
    "        \n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]'):\n",
    "        genre.append(i.text)#Appending genre\n",
    "except NoSuchElementException:\n",
    "    genre.append(i.text)#Appending '-' if genre is not available\n",
    "    \n",
    "dr.close() #Closing the automated  browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4b48a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book name:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['Da Vinci Code,The', 'Harry Potter and the Deathly Hallows', \"Harry Potter and the Philosopher's Stone\", 'Harry Potter and the Order of the Phoenix', 'Fifty Shades of Grey', 'Harry Potter and the Goblet of Fire', 'Harry Potter and the Chamber of Secrets', 'Harry Potter and the Prisoner of Azkaban', 'Angels and Demons', \"Harry Potter and the Half-blood Prince:Children's Edition\", 'Fifty Shades Darker', 'Twilight', 'Girl with the Dragon Tattoo,The:Millennium Trilogy', 'Fifty Shades Freed', 'Lost Symbol,The', 'New Moon', 'Deception Point', 'Eclipse', 'Lovely Bones,The', 'Curious Incident of the Dog in the Night-time,The', 'Digital Fortress', 'Short History of Nearly Everything,A', 'Girl Who Played with Fire,The:Millennium Trilogy', 'Breaking Dawn', 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar', 'Gruffalo,The', \"Jamie's 30-Minute Meals\", 'Kite Runner,The', 'One Day', 'Thousand Splendid Suns,A', \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\", \"Time Traveler's Wife,The\", 'Atonement', \"Bridget Jones's Diary:A Novel\", 'World According to Clarkson,The', \"Captain Corelli's Mandolin\", 'Sound of Laughter,The', 'Life of Pi', 'Billy Connolly', 'Child Called It,A', \"Gruffalo's Child,The\", \"Angela's Ashes:A Memoir of a Childhood\", 'Birdsong', 'Northern Lights:His Dark Materials S.', 'Labyrinth', 'Harry Potter and the Half-blood Prince', 'Help,The', 'Man and Boy', 'Memoirs of a Geisha', \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\", 'Island,The', 'PS, I Love You', 'You are What You Eat:The Plan That Will Change Your Life', 'Shadow of the Wind,The', 'Tales of Beedle the Bard,The', 'Broker,The', \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\", 'Subtle Knife,The:His Dark Materials S.', 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation', \"Delia's How to Cook:(Bk.1)\", 'Chocolat', 'Boy in the Striped Pyjamas,The', \"My Sister's Keeper\", 'Amber Spyglass,The:His Dark Materials S.', 'To Kill a Mockingbird', 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin', 'Dear Fatty', 'Short History of Tractors in Ukrainian,A', 'Hannibal', 'Lord of the Rings,The', 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio', 'Interpretation of Murder,The', 'Sharon Osbourne Extreme:My Autobiography', 'Alchemist,The:A Fable About Following Your Dream', \"At My Mother's Knee ...:and Other Low Joints\", 'Notes from a Small Island', 'Return of the Naked Chef,The', 'Bridget Jones: The Edge of Reason', \"Jamie's Italy\", 'I Can Make You Thin', 'Down Under', 'Summons,The', 'Small Island', 'Nigella Express', 'Brick Lane', \"Memory Keeper's Daughter,The\", 'Room on the Broom', 'About a Boy', 'My Booky Wook', 'God Delusion,The', '\"Beano\" Annual,The', 'White Teeth', 'House at Riverton,The', 'Book Thief,The', 'Nights of Rain and Stars', 'Ghost,The', 'Happy Days with the Naked Chef', 'Hunger Games,The:Hunger Games Trilogy', \"Lost Boy,The:A Foster Child's Search for the Love of a Family\", \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"] \n",
      "\n",
      " Author name:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['Brown, Dan', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'James, E. L.', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'Brown, Dan', 'Rowling, J.K.', 'James, E. L.', 'Meyer, Stephenie', 'Larsson, Stieg', 'James, E. L.', 'Brown, Dan', 'Meyer, Stephenie', 'Brown, Dan', 'Meyer, Stephenie', 'Sebold, Alice', 'Haddon, Mark', 'Brown, Dan', 'Bryson, Bill', 'Larsson, Stieg', 'Meyer, Stephenie', 'Carle, Eric', 'Donaldson, Julia', 'Oliver, Jamie', 'Hosseini, Khaled', 'Nicholls, David', 'Hosseini, Khaled', 'Larsson, Stieg', 'Niffenegger, Audrey', 'McEwan, Ian', 'Fielding, Helen', 'Clarkson, Jeremy', 'Bernieres, Louis de', 'Kay, Peter', 'Martel, Yann', 'Stephenson, Pamela', 'Pelzer, Dave', 'Donaldson, Julia', 'McCourt, Frank', 'Faulks, Sebastian', 'Pullman, Philip', 'Mosse, Kate', 'Rowling, J.K.', 'Stockett, Kathryn', 'Parsons, Tony', 'Golden, Arthur', 'McCall Smith, Alexander', 'Hislop, Victoria', 'Ahern, Cecelia', 'McKeith, Gillian', 'Zafon, Carlos Ruiz', 'Rowling, J.K.', 'Grisham, John', 'Atkins, Robert C.', 'Pullman, Philip', 'Truss, Lynne', 'Smith, Delia', 'Harris, Joanne', 'Boyne, John', 'Picoult, Jodi', 'Pullman, Philip', 'Lee, Harper', 'Gray, John', 'French, Dawn', 'Lewycka, Marina', 'Harris, Thomas', 'Tolkien, J. R. R.', 'Moore, Michael', 'Rubenfeld, Jed', 'Osbourne, Sharon', 'Coelho, Paulo', \"O'Grady, Paul\", 'Bryson, Bill', 'Oliver, Jamie', 'Fielding, Helen', 'Oliver, Jamie', 'McKenna, Paul', 'Bryson, Bill', 'Grisham, John', 'Levy, Andrea', 'Lawson, Nigella', 'Ali, Monica', 'Edwards, Kim', 'Donaldson, Julia', 'Hornby, Nick', 'Brand, Russell', 'Dawkins, Richard', '0', 'Smith, Zadie', 'Morton, Kate', 'Zusak, Markus', 'Binchy, Maeve', 'Harris, Robert', 'Oliver, Jamie', 'Collins, Suzanne', 'Pelzer, Dave', 'Oliver, Jamie'] \n",
      "\n",
      " Volume sold:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['5,094,805', '4,475,152', '4,200,654', '4,179,479', '3,758,936', '3,583,215', '3,484,047', '3,377,906', '3,193,946', '2,950,264', '2,479,784', '2,315,405', '2,233,570', '2,193,928', '2,183,031', '2,152,737', '2,062,145', '2,052,876', '2,005,598', '1,979,552', '1,928,900', '1,852,919', '1,814,784', '1,787,118', '1,783,535', '1,781,269', '1,743,266', '1,629,119', '1,616,068', '1,583,992', '1,555,135', '1,546,886', '1,539,428', '1,508,205', '1,489,403', '1,352,318', '1,310,207', '1,310,176', '1,231,957', '1,217,712', '1,208,711', '1,204,058', '1,184,967', '1,181,503', '1,181,093', '1,153,181', '1,132,336', '1,130,802', '1,126,337', '1,115,549', '1,108,328', '1,107,379', '1,104,403', '1,092,349', '1,090,847', '1,087,262', '1,054,196', '1,037,160', '1,023,688', '1,015,956', '1,009,873', '1,004,414', '1,003,780', '1,002,314', '998,213', '992,846', '986,753', '986,115', '970,509', '967,466', '963,353', '962,515', '959,496', '956,114', '945,640', '931,312', '925,425', '924,695', '906,968', '905,086', '890,847', '869,671', '869,659', '862,602', '856,540', '845,858', '842,535', '828,215', '820,563', '816,907', '816,585', '815,586', '814,370', '809,641', '808,900', '807,311', '794,201', '792,187', '791,507', '791,095'] \n",
      "\n",
      " Publisher:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['Transworld', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Random House', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Transworld', 'Bloomsbury', 'Random House', 'Little, Brown Book', 'Quercus', 'Random House', 'Transworld', 'Little, Brown Book', 'Transworld', 'Little, Brown Book', 'Pan Macmillan', 'Random House', 'Transworld', 'Transworld', 'Quercus', 'Little, Brown Book', 'Penguin', 'Pan Macmillan', 'Penguin', 'Bloomsbury', 'Hodder & Stoughton', 'Bloomsbury', 'Quercus', 'Random House', 'Random House', 'Pan Macmillan', 'Penguin', 'Random House', 'Random House', 'Canongate', 'HarperCollins', 'Orion', 'Pan Macmillan', 'HarperCollins', 'Random House', 'Scholastic Ltd.', 'Orion', 'Bloomsbury', 'Penguin', 'HarperCollins', 'Random House', 'Little, Brown Book', 'Headline', 'HarperCollins', 'Penguin', 'Orion', 'Bloomsbury', 'Random House', 'Random House', 'Scholastic Ltd.', 'Profile Books Group', 'Random House', 'Transworld', 'Random House Childrens Books G', 'Hodder & Stoughton', 'Scholastic Ltd.', 'Random House', 'HarperCollins', 'Random House', 'Penguin', 'Random House', 'HarperCollins', 'Penguin', 'Headline', 'Little, Brown Book', 'HarperCollins', 'Transworld', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Transworld', 'Transworld', 'Random House', 'Headline', 'Random House', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Hodder & Stoughton', 'Transworld', 'D.C. Thomson', 'Penguin', 'Pan Macmillan', 'Transworld', 'Orion', 'Random House', 'Penguin', 'Scholastic Ltd.', 'Orion', 'Penguin'] \n",
      "\n",
      " Genre:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['Crime, Thriller & Adventure', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Romance & Sagas', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Crime, Thriller & Adventure', \"Children's Fiction\", 'Romance & Sagas', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Romance & Sagas', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Popular Science', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Picture Books', 'Picture Books', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Humour: Collections & General', 'General & Literary Fiction', 'Autobiography: General', 'General & Literary Fiction', 'Biography: The Arts', 'Autobiography: General', 'Picture Books', 'Autobiography: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Science Fiction & Fantasy', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'Fitness & Diet', 'General & Literary Fiction', \"Children's Fiction\", 'Crime, Thriller & Adventure', 'Fitness & Diet', 'Young Adult Fiction', 'Usage & Writing Guides', 'Food & Drink: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Popular Culture & Media: General Interest', 'Autobiography: The Arts', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Science Fiction & Fantasy', 'Current Affairs & Issues', 'Crime, Thriller & Adventure', 'Autobiography: The Arts', 'General & Literary Fiction', 'Autobiography: The Arts', 'Travel Writing', 'Food & Drink: General', 'General & Literary Fiction', 'National & Regional Cuisine', 'Fitness & Diet', 'Travel Writing', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'Picture Books', 'General & Literary Fiction', 'Autobiography: The Arts', 'Popular Science', \"Children's Annuals\", 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Food & Drink: General', 'Young Adult Fiction', 'Biography: General', 'Food & Drink: General']\n"
     ]
    }
   ],
   "source": [
    "#Printing Data along with their length\n",
    "print('Book name:-\\nlen:',len(book_name),'\\nData:\\n',book_name,'\\n\\n','Author name:-\\nlen:',len(author_name),'\\nData:\\n',author_name,'\\n\\n','Volume sold:-\\nlen:',len(volumes_sold),'\\nData:\\n',volumes_sold,'\\n\\n','Publisher:-\\nlen:',len(publisher),'\\nData:\\n',publisher,'\\n\\n','Genre:-\\nlen:',len(genre),'\\nData:\\n',genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ea9a4",
   "metadata": {},
   "source": [
    "## Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9459954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the driver\n",
    "dr=wd.Chrome(executable_path=driver_path, options=options)\n",
    "#Opening the website on automated brave browser\n",
    "dr.get('http://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "977a5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the required data\n",
    "name=[]\n",
    "year_span=[]\n",
    "run_time=[]\n",
    "ratings=[]\n",
    "genre=[]\n",
    "votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11f03b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the requried data:\n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a'):\n",
    "        name.append(i.text)#Appending name\n",
    "except NoSuchElementException:\n",
    "    name.append(i.text)#Appending '-' if  name is not available\n",
    "    \n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]'):\n",
    "        year_span.append(i.text)#Appending year span\n",
    "except NoSuchElementException:\n",
    "    year_span.append(i.text)#Appending '-' if year span is not available\n",
    "    \n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/p/span[3]'):\n",
    "        run_time.append(i.text)#Appending run time\n",
    "except NoSuchElementException:\n",
    "    run_time.append(i.text)#Appending '-' if run time is not available\n",
    "    \n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/div/div/span[2]'):\n",
    "        ratings.append(i.text)#Appending ratings\n",
    "except NoSuchElementException:\n",
    "     ratings.append(i.text)#Appending '-' if ratings are not available\n",
    "        \n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/p/span[5]'):\n",
    "        genre.append(i.text)#Appending genre\n",
    "except NoSuchElementException:\n",
    "    genre.append(i.text)#Appending '-' if genre is not available\n",
    "    \n",
    "try:#Handling exception\n",
    "    for i in dr.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/p[4]/span[2]'):\n",
    "        votes.append(i.text)#Appending votes\n",
    "except NoSuchElementException:\n",
    "    votes.append(i.text)#Appending '-' if votes are not available\n",
    "\n",
    "dr.close() #Closing the automated  browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58fba357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['Game of Thrones', 'Stranger Things', 'The Walking Dead', '13 Reasons Why', 'The 100', 'Orange Is the New Black', 'Riverdale', \"Grey's Anatomy\", 'The Flash', 'Arrow', 'Money Heist', 'The Big Bang Theory', 'Black Mirror', 'Sherlock', 'Vikings', 'Pretty Little Liars', 'The Vampire Diaries', 'American Horror Story', 'Breaking Bad', 'Lucifer', 'Supernatural', 'Prison Break', 'How to Get Away with Murder', 'Teen Wolf', 'The Simpsons', 'Once Upon a Time', 'Narcos', 'Daredevil', 'Friends', 'How I Met Your Mother', 'Suits', 'Mr. Robot', 'The Originals', 'Supergirl', 'Gossip Girl', 'Sense8', 'Gotham', 'Westworld', 'Jessica Jones', 'Modern Family', 'Rick and Morty', 'Shadowhunters', 'The End of the F***ing World', 'House of Cards', 'Dark', 'Elite', 'Sex Education', 'Shameless', 'New Girl', 'Agents of S.H.I.E.L.D.', 'You', 'Dexter', 'Fear the Walking Dead', 'Family Guy', 'The Blacklist', 'Lost', 'Peaky Blinders', 'House', 'Quantico', 'Orphan Black', 'Homeland', 'Blindspot', \"DC's Legends of Tomorrow\", \"The Handmaid's Tale\", 'Chilling Adventures of Sabrina', 'The Good Doctor', 'Jane the Virgin', 'Glee', 'South Park', 'Brooklyn Nine-Nine', 'Under the Dome', 'The Umbrella Academy', 'True Detective', 'The OA', 'Desperate Housewives', 'Better Call Saul', 'Bates Motel', 'The Punisher', 'Atypical', 'Dynasty', 'This Is Us', 'The Good Place', 'Iron Fist', 'The Rain', 'Mindhunter', 'Revenge', 'Luke Cage', 'Scandal', 'The Defenders', 'Big Little Lies', 'Insatiable', 'The Mentalist', 'The Crown', 'Chernobyl', 'iZombie', 'Reign', 'A Series of Unfortunate Events', 'Criminal Minds', 'Scream: The TV Series', 'The Haunting of Hill House'] \n",
      "\n",
      " Year Span:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['(2011–2019)', '(2016–2024)', '(2010–2022)', '(2017–2020)', '(2014–2020)', '(2013–2019)', '(2017–2023)', '(2005– )', '(2014–2023)', '(2012–2020)', '(2017–2021)', '(2007–2019)', '(2011– )', '(2010–2017)', '(2013–2020)', '(2010–2017)', '(2009–2017)', '(2011– )', '(2008–2013)', '(2016–2021)', '(2005–2020)', '(2005–2017)', '(2014–2020)', '(2011–2017)', '(1989– )', '(2011–2018)', '(2015–2017)', '(2015–2018)', '(1994–2004)', '(2005–2014)', '(2011–2019)', '(2015–2019)', '(2013–2018)', '(2015–2021)', '(2007–2012)', '(2015–2018)', '(2014–2019)', '(2016–2022)', '(2015–2019)', '(2009–2020)', '(2013– )', '(2016–2019)', '(2017–2019)', '(2013–2018)', '(2017–2020)', '(2018– )', '(2019– )', '(2011–2021)', '(2011–2018)', '(2013–2020)', '(2018–2024)', '(2006–2013)', '(2015–2023)', '(1999– )', '(2013–2023)', '(2004–2010)', '(2013–2022)', '(2004–2012)', '(2015–2018)', '(2013–2017)', '(2011–2020)', '(2015–2020)', '(2016–2022)', '(2017– )', '(2018–2020)', '(2017– )', '(2014–2019)', '(2009–2015)', '(1997– )', '(2013–2021)', '(2013–2015)', '(2019–2023)', '(2014– )', '(2016–2019)', '(2004–2012)', '(2015–2022)', '(2013–2017)', '(2017–2019)', '(2017–2021)', '(2017–2022)', '(2016–2022)', '(2016–2020)', '(2017–2018)', '(2018–2020)', '(2017–2019)', '(2011–2015)', '(2016–2018)', '(2012–2018)', '(2017)', '(2017–2019)', '(2018–2019)', '(2008–2015)', '(2016–2023)', '(2019)', '(2015– )', '(2013–2017)', '(2017–2019)', '(2005– )', '(2015–2019)', '(2018)'] \n",
      "\n",
      " Run time:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['57 min', '51 min', '44 min', '60 min', '43 min', '59 min', '45 min', '41 min', '43 min', '42 min', '70 min', '22 min', '60 min', '88 min', '44 min', '44 min', '43 min', '60 min', '49 min', '42 min', '44 min', '44 min', '43 min', '41 min', '22 min', '60 min', '49 min', '54 min', '22 min', '22 min', '44 min', '49 min', '45 min', '43 min', '42 min', '60 min', '42 min', '62 min', '56 min', '22 min', '23 min', '42 min', '25 min', '51 min', '60 min', '60 min', '45 min', '46 min', '22 min', '45 min', '45 min', '53 min', '44 min', '22 min', '43 min', '44 min', '60 min', '44 min', '42 min', '44 min', '55 min', '42 min', '42 min', '60 min', '60 min', '41 min', '60 min', '44 min', '22 min', '22 min', '43 min', '60 min', '55 min', '60 min', '45 min', '46 min', '45 min', '53 min', '30 min', '42 min', '45 min', '22 min', '55 min', '45 min', '60 min', '44 min', '55 min', '43 min', '50 min', '60 min', '45 min', '43 min', '58 min', '330 min', '42 min', '42 min', '50 min', '42 min', '45 min', '572 min'] \n",
      "\n",
      " Ratings:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['9.2', '8.7', '8.1', '7.5', '7.6', '8.1', '6.6', '7.6', '7.5', '7.5', '8.2', '8.2', '8.8', '9.1', '8.5', '7.4', '7.7', '8', '9.5', '8.1', '8.4', '8.3', '8.1', '7.7', '8.7', '7.7', '8.8', '8.6', '8.9', '8.3', '8.4', '8.5', '8.3', '6.2', '7.5', '8.2', '7.8', '8.5', '7.9', '8.5', '9.1', '6.5', '8', '8.7', '8.7', '7.3', '8.3', '8.6', '7.8', '7.5', '7.7', '8.7', '6.8', '8.2', '8', '8.3', '8.8', '8.7', '6.7', '8.3', '8.3', '7.3', '6.8', '8.4', '7.4', '8', '7.9', '6.8', '8.7', '8.4', '6.5', '7.9', '8.9', '7.8', '7.6', '9', '8.1', '8.5', '8.2', '7.3', '8.7', '8.2', '6.4', '6.3', '8.6', '7.8', '7.3', '7.7', '7.2', '8.5', '6.5', '8.2', '8.6', '9.4', '7.8', '7.4', '7.8', '8.1', '7.1', '8.6'] \n",
      "\n",
      " Genre:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['Action, Adventure, Drama', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Drama, Mystery, Thriller', 'Drama, Mystery, Sci-Fi', 'Comedy, Crime, Drama', 'Crime, Drama, Mystery', 'Drama, Romance', 'Action, Adventure, Drama', 'Action, Adventure, Crime', 'Action, Crime, Drama', 'Comedy, Romance', 'Drama, Mystery, Sci-Fi', 'Crime, Drama, Mystery', 'Action, Adventure, Drama', 'Drama, Mystery, Romance', 'Drama, Fantasy, Horror', 'Drama, Horror, Sci-Fi', 'Crime, Drama, Thriller', 'Crime, Drama, Fantasy', 'Drama, Fantasy, Horror', 'Action, Crime, Drama', 'Crime, Drama, Mystery', 'Action, Drama, Fantasy', 'Animation, Comedy', 'Adventure, Fantasy, Romance', 'Biography, Crime, Drama', 'Action, Crime, Drama', 'Comedy, Romance', 'Comedy, Drama, Romance', 'Comedy, Drama', 'Crime, Drama, Thriller', 'Drama, Fantasy, Horror', 'Action, Adventure, Drama', 'Drama, Romance', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Comedy, Drama, Romance', 'Animation, Adventure, Comedy', 'Action, Drama, Fantasy', 'Adventure, Comedy, Crime', 'Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Thriller', 'Comedy, Drama', 'Comedy, Drama', 'Comedy, Romance', 'Action, Adventure, Drama', 'Crime, Drama, Romance', 'Crime, Drama, Mystery', 'Drama, Horror, Sci-Fi', 'Animation, Comedy', 'Crime, Drama, Mystery', 'Adventure, Drama, Fantasy', 'Crime, Drama', 'Drama, Mystery', 'Crime, Drama, Mystery', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Action, Crime, Drama', 'Action, Adventure, Drama', 'Drama, Sci-Fi, Thriller', 'Drama, Fantasy, Horror', 'Drama', 'Comedy', 'Comedy, Drama, Music', 'Animation, Comedy', 'Comedy, Crime', 'Drama, Mystery, Sci-Fi', 'Action, Adventure, Comedy', 'Crime, Drama, Mystery', 'Drama, Fantasy, Mystery', 'Comedy, Drama, Mystery', 'Crime, Drama', 'Drama, Horror, Mystery', 'Action, Crime, Drama', 'Comedy, Drama', 'Drama', 'Comedy, Drama, Romance', 'Comedy, Drama, Fantasy', 'Action, Adventure, Crime', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Drama, Mystery, Thriller', 'Action, Crime, Drama', 'Drama, Thriller', 'Action, Adventure, Crime', 'Crime, Drama, Mystery', 'Comedy, Drama, Thriller', 'Crime, Drama, Mystery', 'Biography, Drama, History', 'Drama, History, Thriller', 'Comedy, Crime, Drama', 'Drama', 'Adventure, Comedy, Drama', 'Crime, Drama, Mystery', 'Comedy, Crime, Drama', 'Drama, Horror, Mystery'] \n",
      "\n",
      " Votes:-\n",
      "len: 100 \n",
      "Data:\n",
      " ['2,172,090', '1,250,146', '1,031,715', '303,381', '262,567', '310,502', '149,418', '323,542', '359,287', '438,582', '498,424', '831,657', '585,995', '953,951', '553,620', '172,463', '332,597', '328,011', '1,990,519', '337,719', '460,575', '553,794', '158,268', '156,448', '419,200', '230,063', '444,234', '454,757', '1,030,413', '702,866', '427,867', '400,074', '141,276', '126,931', '181,626', '158,330', '235,423', '516,795', '220,040', '452,865', '555,338', '66,868', '204,103', '515,861', '411,530', '84,692', '302,428', '257,131', '234,585', '221,144', '280,111', '740,406', '135,858', '351,599', '264,169', '570,076', '585,452', '481,809', '62,412', '113,651', '350,332', '76,537', '107,655', '247,541', '101,345', '103,867', '54,722', '151,950', '389,775', '334,893', '109,388', '259,021', '597,989', '109,049', '133,436', '582,567', '112,110', '248,877', '96,305', '23,822', '150,209', '173,349', '135,248', '39,359', '307,821', '122,318', '135,260', '76,848', '112,110', '211,131', '30,704', '191,668', '231,045', '802,224', '71,240', '51,922', '63,962', '208,434', '43,376', '259,893']\n"
     ]
    }
   ],
   "source": [
    "#Printing Data along with their length\n",
    "print('Name:-\\nlen:',len(name),'\\nData:\\n',name,'\\n\\n','Year Span:-\\nlen:',len(year_span),'\\nData:\\n',year_span,'\\n\\n','Run time:-\\nlen:',len(run_time),'\\nData:\\n',run_time,'\\n\\n','Ratings:-\\nlen:',len(ratings),'\\nData:\\n',ratings,'\\n\\n','Genre:-\\nlen:',len(genre),'\\nData:\\n',genre,'\\n\\n','Votes:-\\nlen:',len(votes),'\\nData:\\n',votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54f083",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c39c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the driver\n",
    "dr=wd.Chrome(executable_path=driver_path, options=options)\n",
    "#Opening the website on automated brave browser\n",
    "dr.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33be7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on datasets tab\n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/header/nav/ul/li[1]/a').click()\n",
    "except NoSuchElementException:\n",
    "    #Redirecting code to the second button if the code fails to find the first button\n",
    "    try:#Handling exceptions\n",
    "        dr.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]').click()\n",
    "    except NoSuchElementException:\n",
    "        print('Exception Raised...VIEW DATASETS button could not be located ')#Raising exception if second button is not available\n",
    "        \n",
    "    except ElementNotInteractableException:\n",
    "        print('Exception Raised...VIEW DATASETS button is not interactable')#Raising exception if second button is not interactable\n",
    "\n",
    "except ElementNotInteractableException:\n",
    "    #Again redirecting code to the second button if the first button is not interactable\n",
    "    try:#Handling exceptions\n",
    "        dr.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]').click()\n",
    "    except NoSuchElementException:\n",
    "        print('Exception Raised...VIEW DATASETS button could not be located ')#Raising exception if second button is not available\n",
    "        \n",
    "    except ElementNotInteractableException:\n",
    "        print('Exception Raised...VIEW DATASETS button is not interactable')#Raising exception if second button is not interactable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f8eb2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 25  in Rows per page option\n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'//select[@class=\"select-primary select select-sm rounded-full\"]/option[5]').click()\n",
    "except NoSuchElementException:\n",
    "    print('Exception Raised....Unable to locate the Rows per page option')#Raising exception if Rows per page option is not available\n",
    "    \n",
    "except ElementNotInteractableException:\n",
    "    print('Exception Raised....Unable to interact with  Rows per page option')#Raising exception if Rows per page option is not interactable     \n",
    "    \n",
    "#Adding delay to allow the website to load and update the content\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "acf1bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the EXPAND ALL button\n",
    "try:#Handling exceptions\n",
    "    dr.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]').click()\n",
    "except NoSuchElementException:\n",
    "    print('Exception Raised....Unable to locate the EXPAND ALL button')#Raising exception if EXPAND ALL button is not available\n",
    "    \n",
    "except ElementNotInteractableException:\n",
    "    print('Exception Raised....Unable to interact with  EXPAND ALL button')#Raising exception if EXPAND ALL button is not interactable     \n",
    "    \n",
    "#Adding delay to allow the website to load and update the content\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "55a665a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the required data\n",
    "dataset_name=[]\n",
    "data_type=[]\n",
    "task=[]\n",
    "attribute_type=[]\n",
    "no_of_instances=[]\n",
    "no_of_attribute=[]\n",
    "year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aa532b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data\n",
    "for i in range(0,25):#Running for loop for 25 times\n",
    "    try:#Handling exceptions\n",
    "        for a in dr.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]'):\n",
    "            dataset_name.append(a.text)#Appending dataset name\n",
    "    except NoSuchElementException:\n",
    "        dataset_name.append('-')#Appending '-' if dataset name is not found\n",
    "        \n",
    "    try:#Handling exceptions\n",
    "        for a in dr.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]'):\n",
    "            task.append(a.text)#Appendning task\n",
    "    except NoSuchElementException:\n",
    "        task.append('-')#Appending '-' if task if not available\n",
    "        \n",
    "    try:#Handling exceptions\n",
    "        for a in dr.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span'):\n",
    "            data_type.append(a.text)#Appending data type\n",
    "    except NoSuchElementException:\n",
    "        data_type.append('-')#Appending '-' if data type is not found\n",
    "        \n",
    "    try:#Handling exceptions\n",
    "        for a in dr.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span'):\n",
    "            no_of_instances.append(a.text)#Appending number of instances\n",
    "    except NoSuchElementException:\n",
    "        no_of_instances.append('-')#Appending '-' if number of instances are not found\n",
    "        \n",
    "    try:#Handling exceptions\n",
    "        for a in dr.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span'):\n",
    "            no_of_attribute.append(a.text)#Appending number of attributes\n",
    "    except NoSuchElementException:\n",
    "        no_of_attribute.append('-')#Appending '-' if number of attributes are not found\n",
    "        \n",
    "    try:#Handling exceptions\n",
    "        for a in dr.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[2]'):\n",
    "            attribute_type.append(a.text)#Appending attribute type\n",
    "    except NoSuchElementException:\n",
    "        attribute_type.append('-')#Appending '-' if attribute type is not found\n",
    "        \n",
    "    try:#Handling exceptions\n",
    "        for a in dr.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[3]'):\n",
    "            split=a.text.split('/')#Spliting date to get the year\n",
    "            if len(split)==3:#Checking if the text has 3 elements in order to avoid index error\n",
    "                year.append(a.text.split('/')[2])#Appending year\n",
    "            else:\n",
    "                year.append(a.text)#Appending year\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        year.append('-')#Appending '-' if year is not found\n",
    "        \n",
    "    #Clicking on the next button\n",
    "    try:#Handling exceptions\n",
    "        dr.find_element(By.XPATH,'//div[@class=\"btn-group\"]/button[2]').click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"Exception Raised...Unable to locate the button\")#Raising exception if button is not found\n",
    "    except ElementClickInterceptedException:\n",
    "        continue#Ignoring the exception\n",
    "        \n",
    "    #Adding delay to allow the website to load and update the content\n",
    "    time.sleep(5)\n",
    "    \n",
    "dr.close() #Closing the automated  browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bdb013e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:-\n",
      "len: 623 \n",
      "Data:\n",
      " ['Iris', 'Heart Disease', 'Dry Bean Dataset', 'Adult', 'Diabetes', 'Rice (Cammeo and Osmancik)', 'Wine', 'Car Evaluation', 'Breast Cancer Wisconsin (Diagnostic)', 'Mushroom', 'Abalone', 'Breast Cancer', 'Glass Identification', 'Statlog (German Credit Data)', 'Census Income', 'Breast Cancer Wisconsin (Original)', 'Thyroid Disease', 'Auto MPG', 'Optical Recognition of Handwritten Digits', 'Liver Disorders', 'Spambase', 'Zoo', \"Predict students' dropout and academic success\", 'Automobile', 'Lung Cancer', 'Credit Approval', 'Ionosphere', 'Pen-Based Recognition of Handwritten Digits', 'Internet Advertisements', 'Letter Recognition', 'Congressional Voting Records', 'Wine Quality', 'Image Segmentation', 'Hepatitis', 'Yeast', 'Tic-Tac-Toe Endgame', 'Bank Marketing', 'Computer Hardware', 'Reuters-21578 Text Categorization Collection', 'Online Retail II', 'Nursery', 'Connectionist Bench (Sonar, Mines vs. Rocks)', 'Statlog (Australian Credit Approval)', 'Soybean (Large)', 'Covertype', 'Breast Cancer Wisconsin (Prognostic)', 'Statlog Project', 'Student Performance', 'Arrhythmia', 'Soybean (Small)', 'Statlog (Landsat Satellite)', 'Balance Scale', 'Molecular Biology (Promoter Gene Sequences)', 'Statlog (Shuttle)', 'ISOLET', 'Waveform Database Generator (Version 1)', 'Statlog (Vehicle Silhouettes)', 'EEG Database', \"MONK's Problems\", 'Molecular Biology (Splice-junction Gene Sequences)', 'Protein Data', 'Statlog (Heart)', 'Anonymous Microsoft Web Data', 'Ecoli', 'Insurance Company Benchmark (COIL 2000)', 'Dermatology', 'Musk (Version 1)', 'Contraceptive Method Choice', 'Solar Flare', 'Lenses', 'Movie', 'Servo', 'Online Shoppers Purchasing Intention Dataset', 'Air Quality', \"Haberman's Survival\", 'CMU Face Images', 'default of credit card clients', 'Flags', 'Online Retail', 'Chess (King-Rook vs. King-Pawn)', 'SPECT Heart', 'Horse Colic', 'KDD Cup 1999 Data', 'Primary Tumor', 'Estimation of obesity levels based on eating habits and physical condition', 'Census-Income (KDD)', 'US Census Data (1990)', 'Annealing', 'Echocardiogram', 'Balloons', 'Multiple Features', 'Chess (King-Rook vs. King)', 'Lymphography', 'Bach Chorales', 'Challenger USA Space Shuttle O-Ring', 'Labor Relations', 'Cloud', 'Cylinder Bands', 'Audiology (Original)', 'Japanese Credit Screening', 'Chess (King-Rook vs. King-Knight)', 'Audiology (Standardized)', 'NASA Flood Extent Detection', 'Australian Sign Language signs', 'Apartment for rent classified', 'Corel Image Features', 'LED Display Domain', 'Waveform Database Generator (Version 2)', 'Connect-4', 'E. Coli Genes', 'Individual household electric power consumption', 'Page Blocks Classification', 'Post-Operative Patient', 'Molecular Biology (Protein Secondary Structure)', 'Statlog (Image Segmentation)', 'Heart failure clinical records', 'Water Quality Prediction', 'Diabetes 130-US hospitals for years 1999-2008', 'Glioma Grading Clinical and Mutation Features Dataset', 'Traffic Flow Forecasting', 'Connectionist Bench (Vowel Recognition - Deterding Data)', 'Hayes-Roth', 'Human Activity Recognition Using Smartphones', 'Musk (Version 2)', 'Land Mines', 'El Nino', 'Drug Review Dataset (Drugs.com)', 'KDD Cup 1998 Data', 'Shuttle Landing Control', 'Pittsburgh Bridges', 'Forest Fires', 'SPECTF Heart', 'Entree Chicago Recommendation Data', 'MetroPT-3 Dataset', 'Australian Sign Language signs (High Quality)', 'DeFungi', 'Smartphone Dataset for anomaly detection in Crowds.', 'Trains', 'Economic Sanctions', 'DARWIN', 'Early stage diabetes risk prediction dataset.', 'HAR70+', 'Real estate valuation data set', 'Bike Sharing Dataset', 'Mobile Robots', 'Syskill and Webert Web Page Ratings', 'IPUMS Census Database', 'Traffic Flow Forecasting', 'Productivity Prediction of Garment Employees', 'SMS Spam Collection', 'UNIX User Data', 'Online News Popularity', 'Absenteeism at work', 'clickstream data for online shopping', 'Energy efficiency', 'Turkish User Review Dataset', 'seeds', 'Wholesale customers', 'Chess (Domain Theories)', 'HARTH', 'AI4I 2020 Predictive Maintenance Dataset', 'Seoul Bike Sharing Demand', 'WESAD (Wearable Stress and Affect Detection)', 'Tennis Major Tournament Match Statistics', 'Hierarchical Sales Data', 'Concrete Compressive Strength', 'Bar Crawl: Detecting Heavy Drinking', 'Drug consumption (quantified)', 'Beijing PM2.5 Data', 'Appliances energy prediction', 'SoDA', 'Communities and Crime', 'Multivariate Gait Data', 'Beijing Multi-Site Air-Quality Data', 'Taiwanese Bankruptcy Prediction', 'ImageNet', 'Sales_Transactions_Dataset_Weekly', 'Physical Therapy Exercises Dataset', 'Parkinsons', 'MNIST Database of Handwritten Digits', 'Iranian Churn Dataset', 'banknote authentication', 'MAGIC Gamma Telescope', 'South German Credit (UPDATE)', 'Phishing Websites', 'Palmer penguins', 'ElectricityLoadDiagrams20112014', 'Travel Reviews', 'Daily Demand Forecasting Orders', 'Polish companies bankruptcy data', 'Poker Hand', 'Cisco Secure Workload Networks of Computing Hosts', 'Toxicity', 'Epileptic Seizure Recognition', \"Parkinson's Disease Classification\", 'Bosch CNC Machining Dataset', 'News Popularity in Multiple Social Media Platforms', 'NATICUSdroid (Android Permissions) Dataset', 'Educational Process Mining (EPM): A Learning Analytics Data Set', 'Fertility', 'Facebook metrics', 'ISTANBUL STOCK EXCHANGE', 'Combined Cycle Power Plant', 'Chronic_Kidney_Disease', 'Divorce Predictors data set', 'Myocardial infarction complications', 'HCV data', 'Breast Cancer Coimbra', 'accelerometer_gyro_mobile_phone_dataset', 'gene expression cancer RNA-Seq', 'Metro Interstate Traffic Volume', 'Cervical cancer (Risk Factors)', 'MaskReminder', 'in-vehicle coupon recommendation', 'Stock portfolio performance', 'Synchronous Machine Data Set', 'Amazon Access Samples', 'Auction Verification', 'Detect Malware Types', 'Cardiotocography', 'Pedestrian in Traffic Dataset', 'COVID-19 Surveillance', 'Dow Jones Index', 'Gender by Name', 'FMA: A Dataset For Music Analysis', 'Basketball dataset', 'Daily and Sports Activities', 'Human Activity Recognition from Continuous Ambient Sensor Data', 'Open Web Text Corpus', 'Parkinsons Telemonitoring', 'Gas Sensor Array Drift Dataset at Different Concentrations', 'Blood Transfusion Service Center', 'Sentiment Labelled Sentences', 'Drug Review Dataset (Druglib.com)', 'Algerian Forest Fires Dataset', 'Student Academics Performance', 'Website Phishing', 'South German Credit', 'detection_of_IoT_botnet_attacks_N_BaIoT', 'Superconductivty Data', 'Tarvel Review Ratings', 'Electrical Grid Stability Simulated Data', 'Gas Turbine CO and NOx Emission Data Set', 'Tamilnadu Electricity Board Hourly Readings', 'Occupancy Detection', 'Wikipedia Math Essentials', 'Autism Screening Adult', 'Mammographic Mass', 'Hungarian Chickenpox Cases', 'Kitsune Network Attack Dataset', 'CIFAR-10', 'EEG Eye State', 'Student Performance on an entrance examination', 'Dota2 Games Results', 'Residential Building Data Set', 'HIGGS', 'Gas sensor array temperature modulation', 'Dataset based on UWB for Clinical Establishments', 'Cuff-Less Blood Pressure Estimation', 'Othello Domain Theory', 'Las Vegas Strip', 'Ozone Level Detection', 'Smartphone-Based Recognition of Human Activities and Postural Transitions', 'Bone marrow transplant: children', 'Perfume Data', 'Heterogeneity Activity Recognition', 'Alcohol QCM Sensor Dataset', 'Unmanned Aerial Vehicle (UAV) Intrusion Detection', 'NIPS Conference Papers 1987-2015', 'ILPD (Indian Liver Patient Dataset)', 'Open University Learning Analytics dataset', 'BitcoinHeistRansomwareAddressDataset', 'Codon usage', 'Plants', 'Parkinson Speech Dataset with Multiple Types of Sound Recordings', 'Acute Inflammations', 'Condition monitoring of hydraulic systems', 'Mice Protein Expression', 'Cervical Cancer Behavior Risk', 'Vertebral Column', 'Early biomarkers of Parkinson’s disease based on natural connected speech', 'Hepatitis C Virus (HCV) for Egyptian patients', 'MHEALTH Dataset', 'CNNpred: CNN-based stock market prediction using a diverse set of variables', 'Audit Data', 'LT-FS-ID: Intrusion detection in WSNs', 'YouTube Spam Collection', 'Sports articles for objectivity analysis', 'Incident management process enriched event log', 'Facebook Live Sellers in Thailand', 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset', 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014', 'Parking Birmingham', 'Communities and Crime Unnormalized', 'Paper Reviews', 'Facebook Comment Volume Dataset', 'Similarity Prediction', 'Cargo 2000 Freight Tracking and Tracing', 'Buzz in social media', 'EEG Steady-State Visual Evoked Potential Signals', '2D elastodynamic metamaterials', 'Gas sensor array under dynamic gas mixtures', 'Water Treatment Plant', 'QSAR fish toxicity', 'YearPredictionMSD', 'User Knowledge Modeling', 'Bar Crawl: Detecting Heavy Drinking', 'Amazon Commerce reviews set', 'Diabetic Retinopathy Debrecen Data Set', 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet', 'Greenhouse Gas Observing Network', 'Autistic Spectrum Disorder Screening Data for Children', 'Gait Classification', 'YouTube Multiview Video Games Dataset', 'Concrete Slump Test', 'Air quality', 'Bag of Words', 'Skin Segmentation', 'Internet Firewall Data', 'Amphibians', 'EMG data for gestures', 'Period Changer', 'Wave Energy Converters', 'PM2.5 Data of Five Chinese Cities', 'PAMAP2 Physical Activity Monitoring', 'Speaker Accent Recognition', 'Behavior of the urban traffic of the city of Sao Paulo in Brazil', 'Sundanese Twitter Dataset', 'Airfoil Self-Noise', '2.4 GHZ Indoor Channel Measurements', 'Vehicle routing and scheduling problems', 'Stock keeping units', '181 early modern English plays: Transcriptions of early editions in TEI encoding', 'Deepfakes: Medical Image Tamper Detection', 'Activity recognition using wearable physiological measurements', 'Yacht Hydrodynamics', 'Caesarian Section Classification Dataset', 'Gas sensors for home activity monitoring', 'Rice Leaf Diseases', 'Bengali Hate Speech Detection Dataset', 'Swarm Behaviour', 'A study of Asian Religious and Biblical Texts', 'Condition Based Maintenance of Naval Propulsion Plants', 'Bias correction of numerical prediction model temperature forecast', 'Leaf', 'Multi-view Brain Networks', 'Dishonest Internet users Dataset', 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset', 'Simulated data for survival modelling', '3W dataset', 'Steel Plates Faults', 'University', 'Volcanoes on Venus - JARtool experiment', 'Exasens', 'Breast Tissue', 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)', 'Anticancer peptides', 'HTRU2', 'QSAR aquatic toxicity', 'OPPORTUNITY Activity Recognition', 'Health News in Twitter', 'Breath Metabolomics', 'Restaurant & consumer data', 'Wireless Indoor Localization', 'SECOM', 'Geographical Original of Music', 'Crop mapping using fused optical-radar data set', 'Grammatical Facial Expressions', 'Activity recognition with healthy older people using a batteryless wearable sensor', 'BuddyMove Data Set', 'Wheat kernels', 'Thoracic Surgery Data', 'Turkiye Student Evaluation', 'Dresses_Attribute_Sales', 'Physicochemical Properties of Protein Tertiary Structure', 'Climate Model Simulation Crashes', 'Gas Sensor Array Drift Dataset', 'Real-time Election Results: Portugal 2019', 'PPG-DaLiA', 'Dataset for Sensorless Drive Diagnosis', 'Optical Interconnection Network', 'Facebook Large Page-Page Network', 'Gas sensor array exposed to turbulent gas mixtures', 'Qualitative_Bankruptcy', 'SUSY', '3D Road Network (North Jutland, Denmark)', 'Student Loan Relational', 'Wikipedia Math Essentials', 'Somerville Happiness Survey', 'Guitar Chords finger positions', 'Robot Execution Failures', 'Activity Recognition system based on Multisensor data fusion (AReM)', 'Twin gas sensor arrays', 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015', 'Teaching Assistant Evaluation', 'Madelon', 'Daphnet Freezing of Gait', 'Japanese Vowels', 'Weight Lifting Exercises monitored with Inertial Measurement Units', 'Parkinson Dataset with replicated acoustic features', 'Gas sensor array under flow modulation', 'Chemical Composition of Ceramic Samples', 'Mechanical Analysis', 'TV News Channel Commercial Detection Dataset', 'UJIIndoorLoc', 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinsonâ€™s Disease', 'HCC Survival', 'Carbon Nanotubes', 'Arcene', 'URL Reputation', 'Internet Usage Data', 'BlogFeedback', 'GPS Trajectories', 'sEMG for Basic Hand movements', 'Motion Capture Hand Postures', 'Data for Software Engineering Teamwork Assessment in Education Setting', 'Shill Bidding Dataset', 'Shoulder Implant X-Ray Manufacturer Classification', 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone', 'CNAE-9', 'Gas sensor arrays in open sampling settings', 'SkillCraft1 Master Table Dataset', 'KEGG Metabolic Relation Network (Directed)', 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015', 'SML2010', 'Simulated Falls and Daily Living Activities Data Set', 'News Aggregator', 'Dynamic Features of VirusShare Executables', 'Farm Ads', 'Immunotherapy Dataset', ': Simulated Data set of Iraqi tourism places', 'LastFM Asia Social Network', 'Autistic Spectrum Disorder Screening Data for Adolescent', 'User Identification From Walking Activity', 'Dorothea', 'Twitter Data set for Arabic Sentiment Analysis', 'Character Font Images', 'Anuran Calls (MFCCs)', 'seismic-bumps', 'Synthetic Control Chart Time Series', 'Localization Data for Person Activity', 'Sirtuin6 Small Molecules', 'Wisesight Sentiment Corpus', 'DrivFace', 'Ultrasonic flowmeter diagnostics', 'BLE RSSI Dataset for Indoor localization and Navigation', 'EMG Physical Action Data Set', 'Wall-Following Robot Navigation Data', 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer', 'QSAR biodegradation', 'Detect Malacious Executable(AntiVirus)', 'HEPMASS', 'Gesture Phase Segmentation', 'Libras Movement', 'Semeion Handwritten Digit', 'NoisyOffice', 'Cryotherapy Dataset', 'Forest type mapping', 'KEGG Metabolic Reaction Network (Undirected)', 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)', 'Container Crane Controller Data Set', 'Avila', 'Divorce Predictors data set', 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2', 'APS Failure at Scania Trucks', 'Character Trajectories', 'SGEMM GPU kernel performance', 'StoneFlakes', 'QSAR Bioconcentration classes dataset', 'Multimodal Damage Identification for Humanitarian Computing', 'Horton General Hospital', 'EMG dataset in Lower Limb', 'wiki4HE', 'GNFUV Unmanned Surface Vehicles Sensor Data', 'Malware static and dynamic features VxHeaven and Virus Total', 'Artificial Characters', 'Twenty Newsgroups', 'Refractive errors', 'Query Analytics Workloads Dataset', 'MEx', 'Eco-hotel', 'Person Classification Gait Data', 'Legal Case Reports', 'BLOGGER', 'Online Video Characteristics and Transcoding Time Dataset', 'One-hundred plant species leaves data set', 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection', 'Labeled Text Forum Threads Dataset', 'p53 Mutants', 'KASANDR', 'Sentence Classification', 'Planning Relax', 'selfBACK', 'Sponge', 'Urban Land Cover', 'MiniBooNE particle identification', 'UrbanGB, urban road accidents coordinates labelled by the urban center', 'Vicon Physical Action Data Set', 'SCADI', 'YouTube Comedy Slam Preference Data', 'Low Resolution Spectrometer', 'HIV-1 protease cleavage', 'Stock keeping units', 'LSVT Voice Rehabilitation', 'Activity Recognition from Single Chest-Mounted Accelerometer', 'Wave Energy Converters', 'User Profiling and Abusive Language Detection Dataset', 'ICU', 'Physical Unclonable Functions', 'Record Linkage Comparison Patterns', 'Early biomarkers of Parkinsonâ€™s disease based on natural connected speech Data Set', 'Wilt', 'Indoor User Movement Prediction from RSS data', 'Devanagari Handwritten Character Dataset', 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors', 'QSAR oral toxicity', 'IDA2016Challenge', 'GitHub MUSAE', 'REALDISP Activity Recognition Dataset', 'QSAR fish bioconcentration factor (BCF)', 'Gastrointestinal Lesions in Regular Colonoscopy', \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\", 'CLINC150', 'Exasens', 'MicroMass', 'Dataset for ADL Recognition with Wrist-worn Accelerometer', 'DSRC Vehicle Communications', 'Gisette', 'Turkish Spam V01', 'Reuters Transcribed Subset', 'Demospongiae', 'Repeat Consumption Matrices', 'OCT data & Color Fundus Images of Left & Right Eyes', 'UJIIndoorLoc-Mag', 'Quadruped Mammals', 'Predict keywords activities in a online social media', 'Bach Choral Harmony', 'Youtube cookery channels viewers comments in Hinglish', 'Relative location of CT slices on axial axis', 'Quality Assessment of Digital Colposcopies', 'LastFM Asia Social Network', 'Crowdsourced Mapping', 'microblogPCU', 'UJI Pen Characters', 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels', 'Folio', 'Spoken Arabic Digit', 'Dexter', 'Z-Alizadeh Sani', 'Shoulder Implant Manufacture Classification', 'Hill-Valley', 'ICMLA 2014 Accepted Papers Data Set', 'MoCap Hand Postures', 'KDC-4007 dataset Collection', 'OpinRank Review Dataset', 'AAAI 2014 Accepted Papers', 'Kinship', 'First-order theorem proving', 'Russian Corpus of Biographical Texts', 'PEMS-SF', 'Shoulder Implant X-Ray Manufacturer Classification', 'Victorian Era Authorship Attribution', 'Dodgers Loop Sensor', 'Meta-data', 'BLE RSSI dataset for Indoor localization', 'NYSK', 'Nasarian CAD Dataset', 'AAAI 2013 Accepted Papers', 'chipseq', 'Mesotheliomaâ€™s disease data set', 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network', 'Miskolc IIS Hybrid IPS', 'SIFT10M', 'TTC-3600: Benchmark dataset for Turkish text categorization', 'Roman Urdu Data Set', 'Nomao', 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat', 'Mturk User-Perceived Clusters over Images', 'CalIt2 Building People Counts', 'QSAR androgen receptor', 'DBWorld e-mails', 'PubChem Bioassay Data', 'Coil 1999 Competition Data', 'Pseudo Periodic Synthetic Time Series', 'Reuter_50_50', 'MEU-Mobile KSD', 'IIWA14-R820-Gazebo-Dataset-10Trajectories', 'extention of Z-Alizadeh sani dataset', 'Newspaper and magazine images segmentation dataset', 'AutoUniv', 'Discrete Tone Image Dataset', 'Online Handwritten Assamese Characters Dataset', 'Badges', 'Abscisic Acid Signaling Network', 'Northix', 'NSF Research Award Abstracts 1990-2003', 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)', 'Firm-Teacher_Clave-Direction_Classification', 'BAUM-1', 'MSNBC.com Anonymous Web Data', 'Pioneer-1 Mobile Robot Data', 'University of Tehran Question Dataset 2016 (UTQD.2016)', 'PANDOR', 'Qualitative Structure Activity Relationships', 'UbiqLog (smartphone lifelogging)', 'M. Tuberculosis Genes', 'BAUM-2', 'Function Finding', 'Prodigy', 'Document Understanding', 'Connectionist Bench (Nettalk Corpus)', 'UJI Pen Characters (Version 2)', 'Sattriya_Dance_Single_Hand_Gestures Dataset', 'Opinosis Opinion &frasl; Review', 'QtyT40I10D100K', 'chestnut â€“ LARVIC', 'Logic Theorist', 'PMU-UD', 'Undocumented', 'EBL Domain Theories', 'Moral Reasoner', 'DGP2 - The Second Data Generation Program', 'Single elder home monitoring: Gas and position'] \n",
      "\n",
      " Dataset type:-\n",
      "len: 623 \n",
      "Data:\n",
      " ['Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', '', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Domain-Theory', 'Multivariate', 'Multivariate', '', 'Multivariate', 'Multivariate', 'Tabular', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Text', 'Multivariate, Sequential, Time-Series, Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', '', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Sequential, Domain-Theory', 'Multivariate', 'Multivariate', 'Multivariate, Data-Generator', 'Multivariate', '', 'Multivariate', 'Sequential, Domain-Theory', '', 'Multivariate', 'null', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', '', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Image', 'Multivariate', 'Multivariate', 'Multivariate, Sequential, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', '', 'Multivariate', '', '', 'Multivariate', 'Multivariate', 'Multivariate, Domain-Theory', 'Multivariate, Data-Generator', 'Multivariate', 'Image', 'Multivariate, Time-Series', 'Multivariate', '', 'Multivariate, Data-Generator', 'Multivariate, Data-Generator', 'Multivariate, Spatial', '', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Sequential', 'Multivariate', 'Multivariate', 'Other', 'Multivariate', 'Tabular, Multivariate', 'Multivariate', 'null', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Tabular, Multivariate, Other', '', 'Multivariate, Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Transactional, Sequential', 'Tabular, Multivariate, Time-Series', 'Multivariate, Time-Series', 'Image', 'Time-Series', 'Multivariate', '', 'Tabular', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Univariate', '', 'Multivariate, Text', '', 'Other', 'Multivariate, Time-Series', 'Multivariate, Text, Domain-Theory', '', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate, Sequential', 'Multivariate', 'Text', 'Multivariate', 'Multivariate', '', 'Multivariate, Time-Series', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Time-Series', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate, Time-Series', 'Time-Series', 'Multivariate', 'Sequential, Multivariate, Time-Series', 'Multivariate, Time-Series', 'Multivariate', 'Image', 'Multivariate, Time-Series', 'Time-Series', 'Multivariate', 'Image', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'null', 'Tabular', 'Time-Series', 'Multivariate, Text', 'Time-Series', 'Multivariate', 'Multivariate', 'Sequential, Text, Other', 'Tabular', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate, Time-Series, Text', 'Tabular', 'Multivariate, Sequential, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate, Univariate, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate, Univariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Tabular, Sequential, Multivariate, Time-Series', 'Multivariate', 'Multivariate, Sequential, Time-Series', 'Multivariate', 'Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Time-Series, Domain-Theory', 'Tabular', 'Multivariate, Time-Series, Text', 'Multivariate', 'Multivariate, Sequential, Time-Series', 'Multivariate', 'Time-Series', 'Text', 'Multivariate, Time-Series', 'Time-Series', 'Multivariate, Time-Series', 'Multivariate, Sequential, Time-Series', 'Text', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Text', 'Multivariate, Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Sequential', 'Multivariate', 'Multivariate, Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Time-Series', 'null', 'Multivariate', 'Time-Series', 'Multivariate, Sequential, Time-Series', 'Image', 'Multivariate, Sequential, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'null', 'Multivariate, Time-Series', 'Tabular', 'Multivariate', '', 'null', 'Multivariate, Sequential, Time-Series', 'Multivariate, Time-Series', 'Multivariate', 'Univariate, Domain-Theory', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Text', 'Multivariate', 'Multivariate, Sequential, Time-Series', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate, Univariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Sequential, Time-Series', 'Multivariate', 'Tabular', 'Text', 'Multivariate, Text', 'Multivariate, Sequential', 'Multivariate', 'Multivariate, Time-Series', 'Sequential, Time-Series', 'Multivariate, Univariate, Sequential, Time-Series', 'Multivariate', 'Text', 'Multivariate', 'Tabular, Image', 'Multivariate, Sequential', 'Time-Series, Multivariate', 'Multivariate, Time-Series', 'Tabular', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate, Text, Domain-Theory', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate, Text', 'Multivariate', 'Multivariate, Time-Series', 'Text', 'Univariate', 'Multivariate', 'Multivariate', 'Time-Series', 'Tabular', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate, Time-Series', 'Tabular', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Tabular', 'Multivariate', 'Multivariate', 'Multivariate', 'Univariate', 'Multivariate, Time-Series', 'Multivariate', 'Text', 'Multivariate', 'Multivariate, Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Time-Series', 'Multivariate, Time-Series', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Image', 'Multivariate', 'Multivariate', 'Time-Series', 'Sequential', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Text', 'Multivariate, Time-Series', '', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate, Sequential', 'Sequential', 'Multivariate, Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series, Text', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'null', 'Sequential, Text', '', 'Time-Series', 'null', 'Text', 'Multivariate, Time-Series', 'Multivariate, Sequential, Time-Series', 'Multivariate, Time-Series, Domain-Theory', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Univariate', 'Multivariate', 'Multivariate, Time-Series', '', 'Multivariate', 'Multivariate', 'Time-Series', 'Multivariate', 'Sequential, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate, Sequential, Time-Series', 'Multivariate, Text', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate, Univariate, Text', 'Multivariate, Sequential, Time-Series, Domain-Theory', 'Multivariate, Sequential, Time-Series, Text', 'Time-Series', 'Multivariate', 'Multivariate, Time-Series', 'Text', 'Univariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Univariate, Sequential, Time-Series', 'Multivariate', 'Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Time-Series', 'Univariate, Sequential, Time-Series', 'Tabular', 'Multivariate, Text', 'Multivariate', 'Multivariate', 'Multivariate, Sequential, Time-Series', 'Time-Series', 'Multivariate, Sequential', 'Multivariate, Sequential, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Sequential, Time-Series', 'Multivariate, Sequential', 'Multivariate', 'Multivariate', 'Univariate', 'Multivariate', 'Multivariate, Univariate, Text', 'Sequential', 'Univariate, Domain-Theory', 'Multivariate', 'Multivariate, Univariate', 'Multivariate, Sequential, Time-Series', 'Multivariate', 'Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Text', 'Multivariate, Time-Series', '', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', '', 'Multivariate', 'Multivariate', 'Time-Series', '', 'Multivariate', 'Text', 'Multivariate', 'Multivariate', 'null', 'Multivariate', 'Text', 'Multivariate', 'Multivariate', 'Text', 'Univariate', 'Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Univariate', 'Time-Series', 'Multivariate', 'Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Univariate, Sequential, Time-Series', 'Multivariate', 'null', '', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Sequential, Time-Series', 'null', 'Multivariate, Sequential, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Text', 'Multivariate', 'Multivariate', 'Multivariate, Time-Series', 'Sequential, Text', 'Multivariate', 'Text', 'Text', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Sequential, Time-Series', 'Multivariate, Data-Generator', '', 'Sequential', 'Multivariate, Text', 'Domain-Theory', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate, Univariate, Sequential, Text', 'Multivariate, Sequential', 'Text', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'null', 'Multivariate', 'Sequential', 'Multivariate', 'Multivariate', 'Multivariate, Text', '', 'Multivariate', 'Relational', 'Multivariate', 'Text', 'Multivariate, Time-Series', 'Multivariate', 'Text', '', 'Multivariate', 'Sequential, Time-Series', 'Multivariate, Sequential, Text', 'Multivariate', 'Multivariate', 'Sequential', 'Multivariate', 'Text', 'Text', 'Multivariate', 'Text', 'Text', 'Univariate', 'Domain-Theory', 'Multivariate, Text', '', 'Multivariate', 'Text', 'Multivariate', '', '', 'Multivariate, Text, Domain-Theory', 'Multivariate', 'null', 'null', 'null', 'Multivariate', 'Multivariate', 'Multivariate, Sequential', 'Univariate, Text', 'Multivariate', 'Multivariate, Univariate, Text', '', 'Text', 'Multivariate', 'Time-Series', '', '', 'Text', 'Multivariate', '', 'Multivariate', '', 'Time-Series', 'null', '', '', '', 'Multivariate, Sequential', 'Multivariate', '', '', 'null', '', 'Univariate', '', '', '', '', 'Tabular'] \n",
      "\n",
      " Task:-\n",
      "len: 623 \n",
      "Data:\n",
      " ['Iris', 'Heart Disease', 'Dry Bean Dataset', 'Adult', 'Diabetes', 'Rice (Cammeo and Osmancik)', 'Wine', 'Car Evaluation', 'Breast Cancer Wisconsin (Diagnostic)', 'Mushroom', 'Abalone', 'Breast Cancer', 'Glass Identification', 'Statlog (German Credit Data)', 'Census Income', 'Breast Cancer Wisconsin (Original)', 'Thyroid Disease', 'Auto MPG', 'Optical Recognition of Handwritten Digits', 'Liver Disorders', 'Spambase', 'Zoo', \"Predict students' dropout and academic success\", 'Automobile', 'Lung Cancer', 'Credit Approval', 'Ionosphere', 'Pen-Based Recognition of Handwritten Digits', 'Internet Advertisements', 'Letter Recognition', 'Congressional Voting Records', 'Wine Quality', 'Image Segmentation', 'Hepatitis', 'Yeast', 'Tic-Tac-Toe Endgame', 'Bank Marketing', 'Computer Hardware', 'Reuters-21578 Text Categorization Collection', 'Online Retail II', 'Nursery', 'Connectionist Bench (Sonar, Mines vs. Rocks)', 'Statlog (Australian Credit Approval)', 'Soybean (Large)', 'Covertype', 'Breast Cancer Wisconsin (Prognostic)', 'Statlog Project', 'Student Performance', 'Arrhythmia', 'Soybean (Small)', 'Statlog (Landsat Satellite)', 'Balance Scale', 'Molecular Biology (Promoter Gene Sequences)', 'Statlog (Shuttle)', 'ISOLET', 'Waveform Database Generator (Version 1)', 'Statlog (Vehicle Silhouettes)', 'EEG Database', \"MONK's Problems\", 'Molecular Biology (Splice-junction Gene Sequences)', 'Protein Data', 'Statlog (Heart)', 'Anonymous Microsoft Web Data', 'Ecoli', 'Insurance Company Benchmark (COIL 2000)', 'Dermatology', 'Musk (Version 1)', 'Contraceptive Method Choice', 'Solar Flare', 'Lenses', 'Movie', 'Servo', 'Online Shoppers Purchasing Intention Dataset', 'Air Quality', \"Haberman's Survival\", 'CMU Face Images', 'default of credit card clients', 'Flags', 'Online Retail', 'Chess (King-Rook vs. King-Pawn)', 'SPECT Heart', 'Horse Colic', 'KDD Cup 1999 Data', 'Primary Tumor', 'Estimation of obesity levels based on eating habits and physical condition', 'Census-Income (KDD)', 'US Census Data (1990)', 'Annealing', 'Echocardiogram', 'Balloons', 'Multiple Features', 'Chess (King-Rook vs. King)', 'Lymphography', 'Bach Chorales', 'Challenger USA Space Shuttle O-Ring', 'Labor Relations', 'Cloud', 'Cylinder Bands', 'Audiology (Original)', 'Japanese Credit Screening', 'Chess (King-Rook vs. King-Knight)', 'Audiology (Standardized)', 'NASA Flood Extent Detection', 'Australian Sign Language signs', 'Apartment for rent classified', 'Corel Image Features', 'LED Display Domain', 'Waveform Database Generator (Version 2)', 'Connect-4', 'E. Coli Genes', 'Individual household electric power consumption', 'Page Blocks Classification', 'Post-Operative Patient', 'Molecular Biology (Protein Secondary Structure)', 'Statlog (Image Segmentation)', 'Heart failure clinical records', 'Water Quality Prediction', 'Diabetes 130-US hospitals for years 1999-2008', 'Glioma Grading Clinical and Mutation Features Dataset', 'Traffic Flow Forecasting', 'Connectionist Bench (Vowel Recognition - Deterding Data)', 'Hayes-Roth', 'Human Activity Recognition Using Smartphones', 'Musk (Version 2)', 'Land Mines', 'El Nino', 'Drug Review Dataset (Drugs.com)', 'KDD Cup 1998 Data', 'Shuttle Landing Control', 'Pittsburgh Bridges', 'Forest Fires', 'SPECTF Heart', 'Entree Chicago Recommendation Data', 'MetroPT-3 Dataset', 'Australian Sign Language signs (High Quality)', 'DeFungi', 'Smartphone Dataset for anomaly detection in Crowds.', 'Trains', 'Economic Sanctions', 'DARWIN', 'Early stage diabetes risk prediction dataset.', 'HAR70+', 'Real estate valuation data set', 'Bike Sharing Dataset', 'Mobile Robots', 'Syskill and Webert Web Page Ratings', 'IPUMS Census Database', 'Traffic Flow Forecasting', 'Productivity Prediction of Garment Employees', 'SMS Spam Collection', 'UNIX User Data', 'Online News Popularity', 'Absenteeism at work', 'clickstream data for online shopping', 'Energy efficiency', 'Turkish User Review Dataset', 'seeds', 'Wholesale customers', 'Chess (Domain Theories)', 'HARTH', 'AI4I 2020 Predictive Maintenance Dataset', 'Seoul Bike Sharing Demand', 'WESAD (Wearable Stress and Affect Detection)', 'Tennis Major Tournament Match Statistics', 'Hierarchical Sales Data', 'Concrete Compressive Strength', 'Bar Crawl: Detecting Heavy Drinking', 'Drug consumption (quantified)', 'Beijing PM2.5 Data', 'Appliances energy prediction', 'SoDA', 'Communities and Crime', 'Multivariate Gait Data', 'Beijing Multi-Site Air-Quality Data', 'Taiwanese Bankruptcy Prediction', 'ImageNet', 'Sales_Transactions_Dataset_Weekly', 'Physical Therapy Exercises Dataset', 'Parkinsons', 'MNIST Database of Handwritten Digits', 'Iranian Churn Dataset', 'banknote authentication', 'MAGIC Gamma Telescope', 'South German Credit (UPDATE)', 'Phishing Websites', 'Palmer penguins', 'ElectricityLoadDiagrams20112014', 'Travel Reviews', 'Daily Demand Forecasting Orders', 'Polish companies bankruptcy data', 'Poker Hand', 'Cisco Secure Workload Networks of Computing Hosts', 'Toxicity', 'Epileptic Seizure Recognition', \"Parkinson's Disease Classification\", 'Bosch CNC Machining Dataset', 'News Popularity in Multiple Social Media Platforms', 'NATICUSdroid (Android Permissions) Dataset', 'Educational Process Mining (EPM): A Learning Analytics Data Set', 'Fertility', 'Facebook metrics', 'ISTANBUL STOCK EXCHANGE', 'Combined Cycle Power Plant', 'Chronic_Kidney_Disease', 'Divorce Predictors data set', 'Myocardial infarction complications', 'HCV data', 'Breast Cancer Coimbra', 'accelerometer_gyro_mobile_phone_dataset', 'gene expression cancer RNA-Seq', 'Metro Interstate Traffic Volume', 'Cervical cancer (Risk Factors)', 'MaskReminder', 'in-vehicle coupon recommendation', 'Stock portfolio performance', 'Synchronous Machine Data Set', 'Amazon Access Samples', 'Auction Verification', 'Detect Malware Types', 'Cardiotocography', 'Pedestrian in Traffic Dataset', 'COVID-19 Surveillance', 'Dow Jones Index', 'Gender by Name', 'FMA: A Dataset For Music Analysis', 'Basketball dataset', 'Daily and Sports Activities', 'Human Activity Recognition from Continuous Ambient Sensor Data', 'Open Web Text Corpus', 'Parkinsons Telemonitoring', 'Gas Sensor Array Drift Dataset at Different Concentrations', 'Blood Transfusion Service Center', 'Sentiment Labelled Sentences', 'Drug Review Dataset (Druglib.com)', 'Algerian Forest Fires Dataset', 'Student Academics Performance', 'Website Phishing', 'South German Credit', 'detection_of_IoT_botnet_attacks_N_BaIoT', 'Superconductivty Data', 'Tarvel Review Ratings', 'Electrical Grid Stability Simulated Data', 'Gas Turbine CO and NOx Emission Data Set', 'Tamilnadu Electricity Board Hourly Readings', 'Occupancy Detection', 'Wikipedia Math Essentials', 'Autism Screening Adult', 'Mammographic Mass', 'Hungarian Chickenpox Cases', 'Kitsune Network Attack Dataset', 'CIFAR-10', 'EEG Eye State', 'Student Performance on an entrance examination', 'Dota2 Games Results', 'Residential Building Data Set', 'HIGGS', 'Gas sensor array temperature modulation', 'Dataset based on UWB for Clinical Establishments', 'Cuff-Less Blood Pressure Estimation', 'Othello Domain Theory', 'Las Vegas Strip', 'Ozone Level Detection', 'Smartphone-Based Recognition of Human Activities and Postural Transitions', 'Bone marrow transplant: children', 'Perfume Data', 'Heterogeneity Activity Recognition', 'Alcohol QCM Sensor Dataset', 'Unmanned Aerial Vehicle (UAV) Intrusion Detection', 'NIPS Conference Papers 1987-2015', 'ILPD (Indian Liver Patient Dataset)', 'Open University Learning Analytics dataset', 'BitcoinHeistRansomwareAddressDataset', 'Codon usage', 'Plants', 'Parkinson Speech Dataset with Multiple Types of Sound Recordings', 'Acute Inflammations', 'Condition monitoring of hydraulic systems', 'Mice Protein Expression', 'Cervical Cancer Behavior Risk', 'Vertebral Column', 'Early biomarkers of Parkinson’s disease based on natural connected speech', 'Hepatitis C Virus (HCV) for Egyptian patients', 'MHEALTH Dataset', 'CNNpred: CNN-based stock market prediction using a diverse set of variables', 'Audit Data', 'LT-FS-ID: Intrusion detection in WSNs', 'YouTube Spam Collection', 'Sports articles for objectivity analysis', 'Incident management process enriched event log', 'Facebook Live Sellers in Thailand', 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset', 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014', 'Parking Birmingham', 'Communities and Crime Unnormalized', 'Paper Reviews', 'Facebook Comment Volume Dataset', 'Similarity Prediction', 'Cargo 2000 Freight Tracking and Tracing', 'Buzz in social media', 'EEG Steady-State Visual Evoked Potential Signals', '2D elastodynamic metamaterials', 'Gas sensor array under dynamic gas mixtures', 'Water Treatment Plant', 'QSAR fish toxicity', 'YearPredictionMSD', 'User Knowledge Modeling', 'Bar Crawl: Detecting Heavy Drinking', 'Amazon Commerce reviews set', 'Diabetic Retinopathy Debrecen Data Set', 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet', 'Greenhouse Gas Observing Network', 'Autistic Spectrum Disorder Screening Data for Children', 'Gait Classification', 'YouTube Multiview Video Games Dataset', 'Concrete Slump Test', 'Air quality', 'Bag of Words', 'Skin Segmentation', 'Internet Firewall Data', 'Amphibians', 'EMG data for gestures', 'Period Changer', 'Wave Energy Converters', 'PM2.5 Data of Five Chinese Cities', 'PAMAP2 Physical Activity Monitoring', 'Speaker Accent Recognition', 'Behavior of the urban traffic of the city of Sao Paulo in Brazil', 'Sundanese Twitter Dataset', 'Airfoil Self-Noise', '2.4 GHZ Indoor Channel Measurements', 'Vehicle routing and scheduling problems', 'Stock keeping units', '181 early modern English plays: Transcriptions of early editions in TEI encoding', 'Deepfakes: Medical Image Tamper Detection', 'Activity recognition using wearable physiological measurements', 'Yacht Hydrodynamics', 'Caesarian Section Classification Dataset', 'Gas sensors for home activity monitoring', 'Rice Leaf Diseases', 'Bengali Hate Speech Detection Dataset', 'Swarm Behaviour', 'A study of Asian Religious and Biblical Texts', 'Condition Based Maintenance of Naval Propulsion Plants', 'Bias correction of numerical prediction model temperature forecast', 'Leaf', 'Multi-view Brain Networks', 'Dishonest Internet users Dataset', 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset', 'Simulated data for survival modelling', '3W dataset', 'Steel Plates Faults', 'University', 'Volcanoes on Venus - JARtool experiment', 'Exasens', 'Breast Tissue', 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)', 'Anticancer peptides', 'HTRU2', 'QSAR aquatic toxicity', 'OPPORTUNITY Activity Recognition', 'Health News in Twitter', 'Breath Metabolomics', 'Restaurant & consumer data', 'Wireless Indoor Localization', 'SECOM', 'Geographical Original of Music', 'Crop mapping using fused optical-radar data set', 'Grammatical Facial Expressions', 'Activity recognition with healthy older people using a batteryless wearable sensor', 'BuddyMove Data Set', 'Wheat kernels', 'Thoracic Surgery Data', 'Turkiye Student Evaluation', 'Dresses_Attribute_Sales', 'Physicochemical Properties of Protein Tertiary Structure', 'Climate Model Simulation Crashes', 'Gas Sensor Array Drift Dataset', 'Real-time Election Results: Portugal 2019', 'PPG-DaLiA', 'Dataset for Sensorless Drive Diagnosis', 'Optical Interconnection Network', 'Facebook Large Page-Page Network', 'Gas sensor array exposed to turbulent gas mixtures', 'Qualitative_Bankruptcy', 'SUSY', '3D Road Network (North Jutland, Denmark)', 'Student Loan Relational', 'Wikipedia Math Essentials', 'Somerville Happiness Survey', 'Guitar Chords finger positions', 'Robot Execution Failures', 'Activity Recognition system based on Multisensor data fusion (AReM)', 'Twin gas sensor arrays', 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015', 'Teaching Assistant Evaluation', 'Madelon', 'Daphnet Freezing of Gait', 'Japanese Vowels', 'Weight Lifting Exercises monitored with Inertial Measurement Units', 'Parkinson Dataset with replicated acoustic features', 'Gas sensor array under flow modulation', 'Chemical Composition of Ceramic Samples', 'Mechanical Analysis', 'TV News Channel Commercial Detection Dataset', 'UJIIndoorLoc', 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinsonâ€™s Disease', 'HCC Survival', 'Carbon Nanotubes', 'Arcene', 'URL Reputation', 'Internet Usage Data', 'BlogFeedback', 'GPS Trajectories', 'sEMG for Basic Hand movements', 'Motion Capture Hand Postures', 'Data for Software Engineering Teamwork Assessment in Education Setting', 'Shill Bidding Dataset', 'Shoulder Implant X-Ray Manufacturer Classification', 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone', 'CNAE-9', 'Gas sensor arrays in open sampling settings', 'SkillCraft1 Master Table Dataset', 'KEGG Metabolic Relation Network (Directed)', 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015', 'SML2010', 'Simulated Falls and Daily Living Activities Data Set', 'News Aggregator', 'Dynamic Features of VirusShare Executables', 'Farm Ads', 'Immunotherapy Dataset', ': Simulated Data set of Iraqi tourism places', 'LastFM Asia Social Network', 'Autistic Spectrum Disorder Screening Data for Adolescent', 'User Identification From Walking Activity', 'Dorothea', 'Twitter Data set for Arabic Sentiment Analysis', 'Character Font Images', 'Anuran Calls (MFCCs)', 'seismic-bumps', 'Synthetic Control Chart Time Series', 'Localization Data for Person Activity', 'Sirtuin6 Small Molecules', 'Wisesight Sentiment Corpus', 'DrivFace', 'Ultrasonic flowmeter diagnostics', 'BLE RSSI Dataset for Indoor localization and Navigation', 'EMG Physical Action Data Set', 'Wall-Following Robot Navigation Data', 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer', 'QSAR biodegradation', 'Detect Malacious Executable(AntiVirus)', 'HEPMASS', 'Gesture Phase Segmentation', 'Libras Movement', 'Semeion Handwritten Digit', 'NoisyOffice', 'Cryotherapy Dataset', 'Forest type mapping', 'KEGG Metabolic Reaction Network (Undirected)', 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)', 'Container Crane Controller Data Set', 'Avila', 'Divorce Predictors data set', 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2', 'APS Failure at Scania Trucks', 'Character Trajectories', 'SGEMM GPU kernel performance', 'StoneFlakes', 'QSAR Bioconcentration classes dataset', 'Multimodal Damage Identification for Humanitarian Computing', 'Horton General Hospital', 'EMG dataset in Lower Limb', 'wiki4HE', 'GNFUV Unmanned Surface Vehicles Sensor Data', 'Malware static and dynamic features VxHeaven and Virus Total', 'Artificial Characters', 'Twenty Newsgroups', 'Refractive errors', 'Query Analytics Workloads Dataset', 'MEx', 'Eco-hotel', 'Person Classification Gait Data', 'Legal Case Reports', 'BLOGGER', 'Online Video Characteristics and Transcoding Time Dataset', 'One-hundred plant species leaves data set', 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection', 'Labeled Text Forum Threads Dataset', 'p53 Mutants', 'KASANDR', 'Sentence Classification', 'Planning Relax', 'selfBACK', 'Sponge', 'Urban Land Cover', 'MiniBooNE particle identification', 'UrbanGB, urban road accidents coordinates labelled by the urban center', 'Vicon Physical Action Data Set', 'SCADI', 'YouTube Comedy Slam Preference Data', 'Low Resolution Spectrometer', 'HIV-1 protease cleavage', 'Stock keeping units', 'LSVT Voice Rehabilitation', 'Activity Recognition from Single Chest-Mounted Accelerometer', 'Wave Energy Converters', 'User Profiling and Abusive Language Detection Dataset', 'ICU', 'Physical Unclonable Functions', 'Record Linkage Comparison Patterns', 'Early biomarkers of Parkinsonâ€™s disease based on natural connected speech Data Set', 'Wilt', 'Indoor User Movement Prediction from RSS data', 'Devanagari Handwritten Character Dataset', 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors', 'QSAR oral toxicity', 'IDA2016Challenge', 'GitHub MUSAE', 'REALDISP Activity Recognition Dataset', 'QSAR fish bioconcentration factor (BCF)', 'Gastrointestinal Lesions in Regular Colonoscopy', \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\", 'CLINC150', 'Exasens', 'MicroMass', 'Dataset for ADL Recognition with Wrist-worn Accelerometer', 'DSRC Vehicle Communications', 'Gisette', 'Turkish Spam V01', 'Reuters Transcribed Subset', 'Demospongiae', 'Repeat Consumption Matrices', 'OCT data & Color Fundus Images of Left & Right Eyes', 'UJIIndoorLoc-Mag', 'Quadruped Mammals', 'Predict keywords activities in a online social media', 'Bach Choral Harmony', 'Youtube cookery channels viewers comments in Hinglish', 'Relative location of CT slices on axial axis', 'Quality Assessment of Digital Colposcopies', 'LastFM Asia Social Network', 'Crowdsourced Mapping', 'microblogPCU', 'UJI Pen Characters', 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels', 'Folio', 'Spoken Arabic Digit', 'Dexter', 'Z-Alizadeh Sani', 'Shoulder Implant Manufacture Classification', 'Hill-Valley', 'ICMLA 2014 Accepted Papers Data Set', 'MoCap Hand Postures', 'KDC-4007 dataset Collection', 'OpinRank Review Dataset', 'AAAI 2014 Accepted Papers', 'Kinship', 'First-order theorem proving', 'Russian Corpus of Biographical Texts', 'PEMS-SF', 'Shoulder Implant X-Ray Manufacturer Classification', 'Victorian Era Authorship Attribution', 'Dodgers Loop Sensor', 'Meta-data', 'BLE RSSI dataset for Indoor localization', 'NYSK', 'Nasarian CAD Dataset', 'AAAI 2013 Accepted Papers', 'chipseq', 'Mesotheliomaâ€™s disease data set', 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network', 'Miskolc IIS Hybrid IPS', 'SIFT10M', 'TTC-3600: Benchmark dataset for Turkish text categorization', 'Roman Urdu Data Set', 'Nomao', 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat', 'Mturk User-Perceived Clusters over Images', 'CalIt2 Building People Counts', 'QSAR androgen receptor', 'DBWorld e-mails', 'PubChem Bioassay Data', 'Coil 1999 Competition Data', 'Pseudo Periodic Synthetic Time Series', 'Reuter_50_50', 'MEU-Mobile KSD', 'IIWA14-R820-Gazebo-Dataset-10Trajectories', 'extention of Z-Alizadeh sani dataset', 'Newspaper and magazine images segmentation dataset', 'AutoUniv', 'Discrete Tone Image Dataset', 'Online Handwritten Assamese Characters Dataset', 'Badges', 'Abscisic Acid Signaling Network', 'Northix', 'NSF Research Award Abstracts 1990-2003', 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)', 'Firm-Teacher_Clave-Direction_Classification', 'BAUM-1', 'MSNBC.com Anonymous Web Data', 'Pioneer-1 Mobile Robot Data', 'University of Tehran Question Dataset 2016 (UTQD.2016)', 'PANDOR', 'Qualitative Structure Activity Relationships', 'UbiqLog (smartphone lifelogging)', 'M. Tuberculosis Genes', 'BAUM-2', 'Function Finding', 'Prodigy', 'Document Understanding', 'Connectionist Bench (Nettalk Corpus)', 'UJI Pen Characters (Version 2)', 'Sattriya_Dance_Single_Hand_Gestures Dataset', 'Opinosis Opinion &frasl; Review', 'QtyT40I10D100K', 'chestnut â€“ LARVIC', 'Logic Theorist', 'PMU-UD', 'Undocumented', 'EBL Domain Theories', 'Moral Reasoner', 'DGP2 - The Second Data Generation Program', 'Single elder home monitoring: Gas and position'] \n",
      "\n",
      " Attribute type:-\n",
      "len: 623 \n",
      "Data:\n",
      " ['Real', 'Categorical, Integer, Real', 'Integer, Real', 'Categorical, Integer', 'Categorical, Integer', 'Real', 'Integer, Real', 'Categorical', 'Real', 'Categorical', 'Categorical, Integer, Real', 'Categorical', 'Real', 'Categorical, Integer', 'Categorical, Integer', 'Integer', 'Categorical, Real', 'Categorical, Real', 'Integer', 'Categorical, Integer, Real', 'Integer, Real', 'Categorical, Integer', 'N/A', 'Categorical, Integer, Real', 'Integer', 'Categorical, Integer, Real', 'Integer, Real', 'Integer', 'Categorical, Integer, Real', 'Integer', 'Categorical', 'Real', 'Real', 'Categorical, Integer, Real', 'Real', 'Categorical', 'Real', 'Integer', 'Categorical', 'Integer, Real', 'Categorical', 'Real', 'Categorical, Integer, Real', 'Categorical', 'Categorical, Integer', 'Real', 'N/A', 'Integer', 'Categorical, Integer, Real', 'Categorical', 'Integer', 'Categorical', 'Categorical', 'Integer', 'Real', 'Real', 'Integer', 'Categorical, Integer, Real', 'Categorical', 'Categorical', 'N/A', 'Categorical, Real', 'Categorical', 'Real', 'Categorical, Integer', 'Categorical, Integer', 'Integer', 'Categorical, Integer', 'Categorical', 'Categorical', 'N/A', 'Categorical, Integer', 'Integer, Real', 'Real', 'Integer', 'Integer', 'Integer, Real', 'Categorical, Integer', 'Integer, Real', 'Categorical', 'Categorical', 'Categorical, Integer, Real', 'Categorical, Integer', 'Categorical', 'Integer', 'Categorical, Integer', 'Categorical', 'Categorical, Integer, Real', 'Categorical, Integer, Real', 'Categorical', 'Integer, Real', 'Categorical, Integer', 'Categorical', 'Categorical, Integer', 'Integer', 'Categorical, Integer, Real', 'Real', 'Categorical, Integer, Real', 'Categorical', 'Categorical, Real, Integer', 'Categorical, Integer', 'Categorical', '', 'Categorical, Real', 'N/A', 'Real', 'Categorical', 'Real', 'Categorical', 'N/A', 'Real', 'Integer, Real', 'Categorical, Integer', 'Categorical', 'Real', 'Integer, Real', 'N/A', 'Categorical, Integer', 'Real, Categorical, Integer', 'N/A', 'Real', 'Categorical', '', 'Integer', 'Real, Integer', 'Integer, Real', 'Integer', 'Categorical, Integer', 'Categorical', 'Categorical, Integer', 'Real', 'Integer', 'Categorical', 'Real', 'Real', 'Real', 'N/A', 'Categorical', 'N/A', 'N/A', 'N/A', 'Real', 'Integer, Real', 'Integer, Real', 'Categorical, Integer, Real', 'Categorical', 'Categorical, Integer', 'N/A', 'Integer, Real', 'Real', 'N/A', 'Integer, Real', 'Integer, Real', 'Integer, Real', 'Integer, Real', '', 'Real', 'Integer', 'N/A', 'Real', 'Real', 'Integer, Real', 'Real', 'Integer, Real', 'N/A', 'Real', 'Real', 'Real', 'Integer, Real', 'Real', 'N/A', 'Real', 'Real, Categorical, Integer', 'Integer, Real', 'Integer', 'N/A', 'Integer, Real', '', 'Real', 'N/A', 'Integer', 'Real', 'Real', 'Integer, Real', 'Integer', 'N/A', 'Real', 'Real', 'Integer', 'Real', 'Categorical, Integer', 'N/A', 'N/A', 'Integer, Real', 'Integer, Real', 'Real', 'Integer, Real', 'N/A', 'Integer', 'Real', 'Integer', 'Real', 'Real', 'Real', 'Integer', 'Real', 'Integer, Real', 'Integer', 'Real, Categorical', 'Real', 'Integer, Real', 'Integer, Real', 'N/A', 'N/A', 'Real', 'Real', '', 'N/A', 'N/A', 'Real', 'Real', 'N/A', 'Integer, Real', 'N/A', 'Real', 'Integer', 'Real', 'Integer, Real', 'N/A', 'Integer, Real', 'Real', 'Real', '', 'Integer', 'Real', '', 'Integer', 'Integer, Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Integer', 'Integer', 'Real', 'Real', 'N/A', 'Integer, Real', 'N/A', '', 'Real', 'Real', 'Real', 'Real', 'Real', 'N/A', 'Integer', 'Real', 'Real', 'Integer, Real', 'Integer', 'Real', 'Real', 'Real', 'Integer', 'Integer, Real', 'Integer', 'Integer, Real', 'N/A', 'Categorical', 'Integer, Real', 'Categorical, Integer', 'Real', 'Real', 'Integer', 'Real', 'Integer, Real', 'Integer, Real', 'Real', 'Real', 'Real', 'N/A', '', 'Integer', 'Integer', 'Integer', 'Real', 'Real', 'Real', 'Real', 'Integer', 'Integer, Real', 'N/A', 'Integer', 'Integer, Real', 'Integer', 'N/A', 'Real', 'Integer, Real', 'Real', 'Real', 'Integer', 'Real', 'Real', 'Integer, Real', 'Integer', 'Real', 'Integer', 'Real', 'Integer, Real', 'Real', 'Real', 'Integer', 'Real', 'N/A', 'Integer, Real', 'Real', 'N/A', 'Real', 'Integer, Real', 'Real', 'Real', 'Integer, Real', 'N/A', 'Real', 'Real', 'Integer, Real', 'Integer, Real', 'N/A', 'Real', 'Real', 'Real', 'Integer', 'Real', 'Integer', 'N/A', 'Real', 'Integer', 'Real', 'Real', 'Real', 'Integer', '', 'Real', 'Integer, Real', 'Integer, Real', 'Integer, Real', 'Categorical, Integer', 'N/A', 'Integer', 'Real', 'Real', 'N/A', 'Real', 'Real', 'Real', 'Real', 'Real', '', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Integer, Real', '', '', 'Real', 'Real', 'Real', 'Integer, Real', 'Real', 'Real', 'Integer, Real', 'N/A', 'Real', '', 'Real', 'Real', 'N/A', 'Real', 'Integer', 'N/A', 'Integer', 'Real', 'Real', 'Integer', 'Categorical, Integer', 'Real', 'Real', 'Real', 'Real', '', 'Real', 'Real', 'Categorical, Integer, Real', 'Real', 'Integer, Real', 'Real', 'Integer, Real', 'Real', 'Real', 'Integer, Real', 'Categorical, Integer', 'Integer, Real', 'Real', 'Real', 'Real', 'Integer, Real', 'N/A', 'Real', 'Integer, Real', 'Integer', 'Real', 'Integer, Real', 'Integer, Real', 'Real', 'Real', 'Integer', '', 'Integer', '', 'Integer, Real', 'N/A', 'N/A', 'Integer', 'Real', 'Integer', '', 'Integer, Real', 'Real', 'Real', 'Real', 'Real', 'N/A', 'N/A', 'Real', 'Real', 'Integer', 'Real', 'Real', 'Real', 'Integer, Real', 'Real', 'Real', 'Real', 'Real', 'Integer', 'Real', 'Integer, Real', '', 'Integer, Real', 'Integer, Real', 'Real', 'Real', 'Integer', 'Real', 'Integer, Real', 'Real', 'Integer', 'Real', 'N/A', 'Integer', 'Integer', 'Real', '', 'Real', 'Integer, Real', 'Categorical, Integer, Real', 'N/A', 'Integer', 'Real', 'Real', '', 'Real', '', '', 'Integer, Real', 'Real', 'Real', 'Integer', 'Real', 'Integer', 'Integer', 'Real', 'Real', 'Categorical, Integer', '', 'Real', 'Real', 'Real', '', '', 'Integer, Real', 'Categorical', 'Integer, Real', 'Real', 'Real', 'Real', 'N/A', 'Real', 'Integer', 'Real', 'Real', '', 'Real', 'Integer', '', 'N/A', 'Integer', 'N/A', 'Real', 'Integer, Real', 'Real', 'Real', 'N/A', 'Integer', 'Real', '', 'Real', 'Integer', 'N/A', '', 'Integer', 'Real', 'Real', 'Integer, Real', 'Real', 'Integer, Real', '', 'N/A', 'Real', 'Real', 'N/A', '', 'Integer, Real', 'Integer', 'Integer', '', 'Real', 'Integer', 'Integer, Real', 'N/A', 'Real', '', 'Integer, Real', 'Integer', '', '', 'Categorical', 'Real', 'N/A', 'Real', 'Real', '', 'Categorical, Integer', 'Categorical, Integer, Real', 'Integer', '', 'N/A', '', 'Integer', 'Real', 'Integer', 'Integer', 'Integer', 'Integer', '', 'Real', 'Integer', 'Integer', 'Categorical, Integer', 'N/A', '', 'Integer, Real', 'Categorical, Real', 'N/A', 'Real', 'Integer, Real', 'Integer', 'Integer, Real', '', 'Categorical, Integer, Real', '', 'Integer', 'N/A', 'Integer', 'Integer, Real', 'N/A', 'Integer', '', '', 'Categorical', 'Categorical, Real', '', 'Categorical', 'N/A', '', 'N/A', '', 'Real', 'N/A', 'N/A', 'Categorical', 'Integer', 'N/A', '', 'Integer', '', 'N/A', '', 'N/A', 'N/A', 'N/A', 'Real', 'Real'] \n",
      "\n",
      " Number of instances:-\n",
      "len: 623 \n",
      "Data:\n",
      " ['150 Instances', '303 Instances', '13.61K Instances', '48.84K Instances', '', '3.81K Instances', '178 Instances', '1.73K Instances', '569 Instances', '8.12K Instances', '4.18K Instances', '286 Instances', '214 Instances', '1K Instances', '48.84K Instances', '699 Instances', '7.2K Instances', '398 Instances', '5.62K Instances', '345 Instances', '4.6K Instances', '101 Instances', '4.42K Instances', '205 Instances', '32 Instances', '690 Instances', '351 Instances', '10.99K Instances', '3.28K Instances', '20K Instances', '435 Instances', '4.9K Instances', '2.31K Instances', '155 Instances', '1.48K Instances', '958 Instances', '45.21K Instances', '209 Instances', '21.58K Instances', '1.07M Instances', '12.96K Instances', '208 Instances', '690 Instances', '307 Instances', '581.01K Instances', '198 Instances', '', '649 Instances', '452 Instances', '47 Instances', '6.44K Instances', '625 Instances', '106 Instances', '58K Instances', '7.8K Instances', '5K Instances', '946 Instances', '122 Instances', '432 Instances', '3.19K Instances', '', '270 Instances', '37.71K Instances', '336 Instances', '9K Instances', '366 Instances', '476 Instances', '1.47K Instances', '1.39K Instances', '24 Instances', '10K Instances', '167 Instances', '12.33K Instances', '9.36K Instances', '306 Instances', '640 Instances', '30K Instances', '194 Instances', '541.91K Instances', '3.2K Instances', '267 Instances', '368 Instances', '4M Instances', '339 Instances', '2.11K Instances', '299.29K Instances', '2.46M Instances', '798 Instances', '132 Instances', '16 Instances', '2K Instances', '28.06K Instances', '148 Instances', '100 Instances', '23 Instances', '57 Instances', '1.02K Instances', '512 Instances', '226 Instances', '125 Instances', '', '226 Instances', '50K Instances', '6.65K Instances', '10K Instances', '68.04K Instances', '', '5K Instances', '67.56K Instances', '', '2.08M Instances', '5.47K Instances', '90 Instances', '128 Instances', '2.31K Instances', '299 Instances', '705 Instances', '101.77K Instances', '839 Instances', '2.1K Instances', '528 Instances', '160 Instances', '10.3K Instances', '6.6K Instances', '338 Instances', '178.08K Instances', '215.06K Instances', '191.78K Instances', '15 Instances', '108 Instances', '517 Instances', '267 Instances', '50.67K Instances', '1.52M Instances', '2.57K Instances', '9.11K Instances', '14.22K Instances', '10 Instances', '', '174 Instances', '520 Instances', '2.26M Instances', '414 Instances', '17.39K Instances', '', '332 Instances', '256.93K Instances', '2.1K Instances', '1.2K Instances', '5.57K Instances', '', '39.8K Instances', '740 Instances', '165.47K Instances', '768 Instances', '37.06K Instances', '210 Instances', '440 Instances', '', '6.46M Instances', '10K Instances', '8.76K Instances', '63M Instances', '127 Instances', '1.8K Instances', '1.03K Instances', '14.06M Instances', '1.89K Instances', '43.82K Instances', '19.74K Instances', '1.8K Instances', '1.99K Instances', '181.8K Instances', '420.77K Instances', '6.82K Instances', '14M Instances', '811 Instances', '268.88K Instances', '197 Instances', '70K Instances', '3.15K Instances', '1.37K Instances', '19.02K Instances', '1K Instances', '2.46K Instances', '344 Instances', '370 Instances', '980 Instances', '60 Instances', '10.5K Instances', '1.03M Instances', '1M Instances', '171 Instances', '11.5K Instances', '756 Instances', '2.7K Instances', '93.24K Instances', '29.33K Instances', '230.32K Instances', '100 Instances', '500 Instances', '536 Instances', '9.57K Instances', '400 Instances', '170 Instances', '1.7K Instances', '615 Instances', '116 Instances', '31.99K Instances', '801 Instances', '48.2K Instances', '858 Instances', '7.6K Instances', '12.68K Instances', '315 Instances', '557 Instances', '30K Instances', '2.04K Instances', '7.11K Instances', '2.13K Instances', '4.76K Instances', '14 Instances', '750 Instances', '147.27K Instances', '106.57K Instances', '10K Instances', '9.12K Instances', '13.96M Instances', '8.01M Instances', '5.88K Instances', '13.91K Instances', '748 Instances', '3K Instances', '4.14K Instances', '244 Instances', '300 Instances', '1.35K Instances', '1K Instances', '7.06M Instances', '21.26K Instances', '5.46K Instances', '10K Instances', '36.73K Instances', '45.78K Instances', '20.56K Instances', '731 Instances', '704 Instances', '961 Instances', '521 Instances', '27.17M Instances', '60K Instances', '14.98K Instances', '666 Instances', '102.94K Instances', '372 Instances', '11M Instances', '4.1M Instances', '608 Instances', '12K Instances', '', '504 Instances', '2.54K Instances', '10.93K Instances', '187 Instances', '560 Instances', '43.93M Instances', '125 Instances', '17.26K Instances', '11.46K Instances', '583 Instances', '', '2.92M Instances', '13.03K Instances', '22.63K Instances', '1.04K Instances', '120 Instances', '2.21K Instances', '1.08K Instances', '72 Instances', '310 Instances', '130 Instances', '1.39K Instances', '120 Instances', '1.99K Instances', '777 Instances', '182 Instances', '1.96K Instances', '1K Instances', '141.71K Instances', '7.05K Instances', '15.63M Instances', '314.08K Instances', '35.72K Instances', '2.22K Instances', '405 Instances', '40.95K Instances', '200 Instances', '3.94K Instances', '140K Instances', '9.2K Instances', '20.52K Instances', '4.18M Instances', '527 Instances', '908 Instances', '515.35K Instances', '403 Instances', '14.06M Instances', '1.5K Instances', '1.15K Instances', '77 Instances', '2.92K Instances', '292 Instances', '48 Instances', '120K Instances', '103 Instances', '9.36K Instances', '8M Instances', '245.06K Instances', '65.53K Instances', '189 Instances', '30K Instances', '90 Instances', '288K Instances', '52.85K Instances', '3.85M Instances', '329 Instances', '135 Instances', '2.51K Instances', '1.5K Instances', '7.84K Instances', '18 Instances', '2.28K Instances', '181 Instances', '20K Instances', '4.48K Instances', '308 Instances', '80 Instances', '919.44K Instances', '120 Instances', '4.5K Instances', '24.02K Instances', '590 Instances', '11.93K Instances', '7.75K Instances', '340 Instances', '70 Instances', '322 Instances', '800 Instances', '120K Instances', '1.98K Instances', '1.94K Instances', '285 Instances', '', '399 Instances', '106 Instances', '5.74K Instances', '1.85K Instances', '17.9K Instances', '546 Instances', '2.55K Instances', '58K Instances', '104 Instances', '138 Instances', '2K Instances', '1.57K Instances', '1.06K Instances', '325.83K Instances', '27.97K Instances', '75.13K Instances', '249 Instances', '314 Instances', '470 Instances', '5.82K Instances', '501 Instances', '45.73K Instances', '540 Instances', '13.91K Instances', '21.64K Instances', '8.3M Instances', '58.51K Instances', '640 Instances', '22.47K Instances', '180 Instances', '250 Instances', '5M Instances', '434.87K Instances', '1K Instances', '731 Instances', '143 Instances', '2.63K Instances', '463 Instances', '42.24K Instances', '640 Instances', '217 Instances', '151 Instances', '4.4K Instances', '237 Instances', '640 Instances', '39.24K Instances', '240 Instances', '58 Instances', '88 Instances', '209 Instances', '129.69K Instances', '21.05K Instances', '40 Instances', '165 Instances', '10.72K Instances', '900 Instances', '2.4M Instances', '10.1K Instances', '60.02K Instances', '163 Instances', '3K Instances', '78.1K Instances', '74 Instances', '6.32K Instances', '597 Instances', '153.54K Instances', '1.08K Instances', '18K Instances', '3.4K Instances', '53.41K Instances', '1.71M Instances', '4.14K Instances', '3.06K Instances', '422.94K Instances', '107.89K Instances', '4.14K Instances', '90 Instances', '232 Instances', '7.62K Instances', '104 Instances', '', '1.95K Instances', '2K Instances', '745K Instances', '7.2K Instances', '2.58K Instances', '600 Instances', '164.86K Instances', '100 Instances', '26.74K Instances', '606 Instances', '540 Instances', '6.61K Instances', '10K Instances', '5.46K Instances', '1.54K Instances', '1.06K Instances', '373 Instances', '10.5M Instances', '9.9K Instances', '360 Instances', '1.59K Instances', '216 Instances', '90 Instances', '326 Instances', '65.55K Instances', '165.63K Instances', '15 Instances', '20.87K Instances', '170 Instances', '10.19K Instances', '60K Instances', '2.86K Instances', '241.6K Instances', '79 Instances', '779 Instances', '5.88K Instances', '139 Instances', '132 Instances', '913 Instances', '1.67K Instances', '2.96K Instances', '6K Instances', '20K Instances', '467 Instances', '260K Instances', '6.26K Instances', '401 Instances', '48 Instances', '', '100 Instances', '168.29K Instances', '1.6K Instances', '111.74K Instances', '200 Instances', '16.77K Instances', '17.76M Instances', '', '182 Instances', '26.14K Instances', '76 Instances', '168 Instances', '130.07K Instances', '360.18K Instances', '3K Instances', '70 Instances', '1.14M Instances', '531 Instances', '6.59K Instances', '2.28K Instances', '126 Instances', '', '288K Instances', '65.92K Instances', '', '6M Instances', '5.75M Instances', '', '4.89K Instances', '13.2K Instances', '92K Instances', '2.75K Instances', '8.99K Instances', '76K Instances', '37.7K Instances', '1.42K Instances', '1.06K Instances', '76 Instances', '403 Instances', '23.7K Instances', '399 Instances', '931 Instances', '', '10K Instances', '13.5K Instances', '826 Instances', '200 Instances', '503 Instances', '130K Instances', '50 Instances', '40K Instances', '', '51 Instances', '5.67K Instances', '9.8K Instances', '53.5K Instances', '287 Instances', '7.62K Instances', '10.55K Instances', '221.58K Instances', '1.36K Instances', '12.23K Instances', '637 Instances', '8.8K Instances', '2.6K Instances', '303 Instances', '597 Instances', '606 Instances', '105 Instances', '78.1K Instances', '4.01K Instances', '', '399 Instances', '104 Instances', '6.12K Instances', '200 Instances', '440 Instances', '597 Instances', '93.6K Instances', '50.4K Instances', '528 Instances', '23.57K Instances', '10.42K Instances', '150 Instances', '150 Instances', '4.96K Instances', '324 Instances', '1.08K Instances', '1.54K Instances', '11.16M Instances', '3.6K Instances', '20K Instances', '34.47K Instances', '306 Instances', '180 Instances', '10.08K Instances', '1.69K Instances', '64 Instances', '', '340 Instances', '100K Instances', '2.5K Instances', '2.86K Instances', '', '303 Instances', '101 Instances', '', '71 Instances', '8.24K Instances', '294 Instances', '300 Instances', '115 Instances', '129K Instances', '3.92K Instances', '10.8K Instances', '1.18K Instances', '989.82K Instances', '', '1.18K Instances', '', '', '9.78M Instances', '', '1.05K Instances', '352 Instances', '', '', '20.01K Instances', '11.64K Instances', '1.45K Instances', '51 Instances', '3.96M Instances', '1.45K Instances', '', '5.18K Instances', '', '', '202 Instances', '', '444.63K Instances'] \n",
      "\n",
      " Number of attribute:-\n",
      "len: 623 \n",
      "Data:\n",
      " ['4 Attributes', '13 Attributes', '17 Attributes', '14 Attributes', '20 Attributes', '8 Attributes', '13 Attributes', '6 Attributes', '30 Attributes', '22 Attributes', '8 Attributes', '9 Attributes', '9 Attributes', '20 Attributes', '14 Attributes', '9 Attributes', '5 Attributes', '7 Attributes', '64 Attributes', '5 Attributes', '57 Attributes', '16 Attributes', '36 Attributes', '25 Attributes', '56 Attributes', '15 Attributes', '34 Attributes', '16 Attributes', '1.56K Attributes', '16 Attributes', '16 Attributes', '12 Attributes', '19 Attributes', '19 Attributes', '8 Attributes', '9 Attributes', '17 Attributes', '9 Attributes', '5 Attributes', '8 Attributes', '8 Attributes', '60 Attributes', '14 Attributes', '35 Attributes', '54 Attributes', '34 Attributes', '', '33 Attributes', '279 Attributes', '35 Attributes', '36 Attributes', '4 Attributes', '58 Attributes', '8 Attributes', '617 Attributes', '21 Attributes', '18 Attributes', '4 Attributes', '6 Attributes', '61 Attributes', '', '13 Attributes', '294 Attributes', '8 Attributes', '86 Attributes', '33 Attributes', '168 Attributes', '9 Attributes', '10 Attributes', '4 Attributes', '', '4 Attributes', '18 Attributes', '15 Attributes', '3 Attributes', '', '24 Attributes', '30 Attributes', '8 Attributes', '36 Attributes', '22 Attributes', '27 Attributes', '42 Attributes', '17 Attributes', '17 Attributes', '40 Attributes', '68 Attributes', '38 Attributes', '12 Attributes', '4 Attributes', '649 Attributes', '6 Attributes', '18 Attributes', '6 Attributes', '4 Attributes', '16 Attributes', '10 Attributes', '39 Attributes', '', '', '22 Attributes', '69 Attributes', '', '15 Attributes', '22 Attributes', '89 Attributes', '7 Attributes', '40 Attributes', '42 Attributes', '', '9 Attributes', '10 Attributes', '8 Attributes', '', '19 Attributes', '13 Attributes', '', '47 Attributes', '23 Attributes', '', '10 Attributes', '5 Attributes', '561 Attributes', '168 Attributes', '4 Attributes', '12 Attributes', '6 Attributes', '481 Attributes', '6 Attributes', '13 Attributes', '13 Attributes', '44 Attributes', '', '15 Attributes', '22 Attributes', '', '', '32 Attributes', '', '451 Attributes', '17 Attributes', '6 Attributes', '7 Attributes', '16 Attributes', '', '5 Attributes', '61 Attributes', '', '15 Attributes', '', '', '61 Attributes', '21 Attributes', '14 Attributes', '8 Attributes', '', '7 Attributes', '8 Attributes', '', '8 Attributes', '14 Attributes', '14 Attributes', '12 Attributes', '42 Attributes', '237 Attributes', '9 Attributes', '15 Attributes', '32 Attributes', '13 Attributes', '29 Attributes', '', '128 Attributes', '7 Attributes', '18 Attributes', '96 Attributes', '', '53 Attributes', '', '23 Attributes', '', '13 Attributes', '5 Attributes', '11 Attributes', '21 Attributes', '30 Attributes', '', '140.26K Attributes', '11 Attributes', '13 Attributes', '64 Attributes', '11 Attributes', '', '1.2K Attributes', '179 Attributes', '754 Attributes', '3 Attributes', '11 Attributes', '86 Attributes', '13 Attributes', '10 Attributes', '19 Attributes', '8 Attributes', '4 Attributes', '25 Attributes', '54 Attributes', '124 Attributes', '14 Attributes', '10 Attributes', '8 Attributes', '20.53K Attributes', '9 Attributes', '36 Attributes', '', '23 Attributes', '12 Attributes', '5 Attributes', '20K Attributes', '7 Attributes', '280 Attributes', '23 Attributes', '14 Attributes', '7 Attributes', '16 Attributes', '4 Attributes', '518 Attributes', '7 Attributes', '5.63K Attributes', '37 Attributes', '', '26 Attributes', '129 Attributes', '5 Attributes', '', '8 Attributes', '12 Attributes', '22 Attributes', '10 Attributes', '21 Attributes', '115 Attributes', '81 Attributes', '25 Attributes', '14 Attributes', '11 Attributes', '5 Attributes', '7 Attributes', '1.07K Attributes', '21 Attributes', '6 Attributes', '20 Attributes', '7 Attributes', '', '15 Attributes', '11 Attributes', '116 Attributes', '105 Attributes', '28 Attributes', '20 Attributes', '8 Attributes', '3 Attributes', '', '20 Attributes', '73 Attributes', '561 Attributes', '39 Attributes', '2 Attributes', '16 Attributes', '8 Attributes', '55 Attributes', '5.81K Attributes', '10 Attributes', '', '10 Attributes', '69 Attributes', '70 Attributes', '26 Attributes', '6 Attributes', '43.68K Attributes', '82 Attributes', '19 Attributes', '6 Attributes', '65 Attributes', '29 Attributes', '23 Attributes', '84 Attributes', '18 Attributes', '4 Attributes', '5 Attributes', '59 Attributes', '36 Attributes', '12 Attributes', '6 Attributes', '', '4 Attributes', '147 Attributes', '10 Attributes', '54 Attributes', '', '98 Attributes', '77 Attributes', '16 Attributes', '1 Attributes', '19 Attributes', '38 Attributes', '7 Attributes', '90 Attributes', '5 Attributes', '3 Attributes', '10K Attributes', '20 Attributes', '7 Attributes', '5.23K Attributes', '21 Attributes', '321 Attributes', '1M Attributes', '10 Attributes', '15 Attributes', '100K Attributes', '4 Attributes', '12 Attributes', '23 Attributes', '6 Attributes', '1.18K Attributes', '49 Attributes', '86 Attributes', '52 Attributes', '12 Attributes', '18 Attributes', '1 Attributes', '6 Attributes', '5 Attributes', '9 Attributes', '9 Attributes', '', '200K Attributes', '533 Attributes', '7 Attributes', '5 Attributes', '11 Attributes', '', '', '2.4K Attributes', '8.27K Attributes', '16 Attributes', '7 Attributes', '16 Attributes', '70 Attributes', '5 Attributes', '9 Attributes', '25 Attributes', '8 Attributes', '27 Attributes', '17 Attributes', '', '4 Attributes', '10 Attributes', '561 Attributes', '2 Attributes', '9 Attributes', '9 Attributes', '242 Attributes', '25K Attributes', '1.66K Attributes', '47 Attributes', '7 Attributes', '591 Attributes', '68 Attributes', '175 Attributes', '100 Attributes', '9 Attributes', '7 Attributes', '15 Attributes', '17 Attributes', '33 Attributes', '13 Attributes', '9 Attributes', '18 Attributes', '128 Attributes', '29 Attributes', '11 Attributes', '49 Attributes', '10 Attributes', '4.71K Attributes', '150K Attributes', '7 Attributes', '18 Attributes', '4 Attributes', '', '1.07K Attributes', '7 Attributes', '5 Attributes', '90 Attributes', '6 Attributes', '480K Attributes', '12 Attributes', '5 Attributes', '500 Attributes', '9 Attributes', '12 Attributes', '152 Attributes', '46 Attributes', '120.43K Attributes', '19 Attributes', '8 Attributes', '12 Attributes', '529 Attributes', '7 Attributes', '49 Attributes', '8 Attributes', '10K Attributes', '3.23M Attributes', '72 Attributes', '281 Attributes', '15 Attributes', '2.5K Attributes', '38 Attributes', '102 Attributes', '13 Attributes', '1 Attributes', '25 Attributes', '857 Attributes', '1.95M Attributes', '20 Attributes', '24 Attributes', '9 Attributes', '24 Attributes', '138 Attributes', '5 Attributes', '482 Attributes', '54.88K Attributes', '8 Attributes', '16 Attributes', '7.84K Attributes', '21 Attributes', '', '100K Attributes', '2 Attributes', '411 Attributes', '22 Attributes', '19 Attributes', '', '8 Attributes', '', '4 Attributes', '6.4K Attributes', '173 Attributes', '15 Attributes', '8 Attributes', '24 Attributes', '65 Attributes', '41 Attributes', '513 Attributes', '28 Attributes', '50 Attributes', '91 Attributes', '256 Attributes', '216 Attributes', '7 Attributes', '27 Attributes', '29 Attributes', '18 Attributes', '3 Attributes', '10 Attributes', '54 Attributes', '6 Attributes', '171 Attributes', '3 Attributes', '18 Attributes', '8 Attributes', '14 Attributes', '', '6 Attributes', '5 Attributes', '53 Attributes', '5 Attributes', '1.09K Attributes', '7 Attributes', '', '79 Attributes', '8 Attributes', '710 Attributes', '1 Attributes', '321 Attributes', '', '6 Attributes', '11 Attributes', '64 Attributes', '', '9 Attributes', '5.41K Attributes', '2.16M Attributes', '', '13 Attributes', '6 Attributes', '45 Attributes', '148 Attributes', '50 Attributes', '2 Attributes', '27 Attributes', '206 Attributes', '3 Attributes', '102 Attributes', '1 Attributes', '9 Attributes', '309 Attributes', '', '49 Attributes', '3 Attributes', '', '129 Attributes', '12 Attributes', '', '6 Attributes', '4 Attributes', '', '', '1.02K Attributes', '171 Attributes', '4.01K Attributes', '120 Attributes', '7 Attributes', '698 Attributes', '5 Attributes', '', '4 Attributes', '1.3K Attributes', '3 Attributes', '5 Attributes', '5K Attributes', '2 Attributes', '', '', '21K Attributes', '2 Attributes', '13 Attributes', '72 Attributes', '35 Attributes', '17 Attributes', '3 Attributes', '386 Attributes', '69 Attributes', '7.84K Attributes', '29 Attributes', '20 Attributes', '', '8.52K Attributes', '20 Attributes', '13 Attributes', '20K Attributes', '56 Attributes', '1 Attributes', '101 Attributes', '5 Attributes', '38 Attributes', '', '', '6 Attributes', '12 Attributes', '51 Attributes', '2 Attributes', '138.67K Attributes', '1 Attributes', '1K Attributes', '3 Attributes', '22 Attributes', '5 Attributes', '7 Attributes', '52 Attributes', '5 Attributes', '', '34 Attributes', '22 Attributes', '67 Attributes', '128 Attributes', '4.81K Attributes', '2 Attributes', '120 Attributes', '5 Attributes', '500 Attributes', '4 Attributes', '1.02K Attributes', '4.7K Attributes', '', '17 Attributes', '', '10K Attributes', '71 Attributes', '', '59 Attributes', '', '', '11 Attributes', '', '1 Attributes', '43 Attributes', '200 Attributes', '', '3.92K Attributes', '20 Attributes', '', '', '', '3 Attributes', '', '', '', '', '', '', '', '', '4 Attributes', '', '', '', '4 Attributes', '3 Attributes', '', '9 Attributes', '', '', '', '', '16 Attributes'] \n",
      "\n",
      " Year:-\n",
      "len: 623 \n",
      "Data:\n",
      " ['1988', '1988', '2020', '1996', 'N/A', '2019', '1991', '1997', '1995', '1987', '1995', '1988', '1987', '1994', '1996', '1992', '1987', '1993', '1998', '1990', '1999', '1990', '2021', '1987', '1992', 'N/A', '1989', '1998', '1998', '1991', '1987', '2009', '1990', '1988', '1996', '1991', '2012', '1987', '1997', '2019', '1997', 'N/A', 'N/A', '1988', '1998', '1995', '1992', '2014', '1998', '1987', '1993', '1994', '1990', 'N/A', '1994', '1988', 'N/A', '1999', '1992', '1992', 'N/A', 'N/A', '1998', '1996', '2000', '1998', '1994', '1997', '1989', '1990', '1999', '1993', '2018', '2016', '1999', '1999', '2016', '1990', '2015', '1989', '2001', '1989', '1999', '1988', '2019', '2000', 'N/A', 'N/A', '1989', 'N/A', 'N/A', '1994', '1988', 'N/A', '1993', '1988', '1989', '1995', '1987', '1992', '1988', '1992', '2023', '1999', '2019', '1999', '1988', '1988', '1995', '2001', '2012', '1995', '1993', 'N/A', '1990', '2020', '2022', '2014', '2022', '2021', 'N/A', '1989', '2012', '1994', '2022', '1999', '2018', '1998', '1988', '1990', '2008', '2001', '2000', '2023', '2002', '2023', '2021', '1994', 'N/A', '2022', '2020', '2023', '2018', '2013', '1995', '1998', '1999', '2022', '2020', '2012', 'N/A', '2015', '2018', '2019', '2012', '2023', '2012', '2014', 'N/A', '2023', '2020', '2020', '2018', '2014', '2021', '2007', '2020', '2016', '2017', '2017', '2022', '2009', '2022', '2019', '2020', '2021', '2017', '2022', '2008', '2021', '2020', '2013', '2007', '2020', '2015', '2021', '2015', '2018', '2017', '2016', '2007', '2022', '2022', '2017', '2018', '2022', '2018', '2022', '2015', '2013', '2016', '2013', '2014', '2015', '2019', '2020', '2020', '2018', '2022', '2016', '2019', '2017', '2022', '2020', '2016', '2021', '2011', '2022', '2019', '2010', '2019', '2020', '2014', '2020', '2017', '2019', '2013', '2019', '2021', '2009', '2013', '2008', '2015', '2018', '2019', '2018', '2016', '2019', '2018', '2018', '2018', '2018', '2019', '2013', '2016', '2021', '2017', '2007', '2021', '2019', '2021', '2013', '2018', '2016', '2018', '2014', '2019', '2022', '2015', '1991', '2017', '2008', '2015', '2020', '2014', '2015', '2019', '2020', '2016', '2012', '2015', '2020', '2020', '2008', '2014', '2009', '2018', '2015', '2019', '2011', '2017', '2019', '2014', '2019', '2018', '2022', '2017', '2018', '2019', '2019', '2019', '2015', '2019', '2011', '2017', '2016', '2022', '2016', '2013', '2018', '2021', '2015', '1993', '2019', '2011', '2013', '2020', '2011', '2014', '2017', '2015', '2017', '2020', '2013', '2009', '2016', '2008', '2012', '2019', '2020', '2019', '2022', '2019', '2017', '2012', '2020', '2018', '2021', '2014', '2018', '2019', '2019', '2022', '2020', '2019', '2013', '2018', '2016', '2019', '2022', '2020', '2019', '2014', '2020', '2014', '2020', '2018', '2020', '2018', '2019', '2010', '1988', 'N/A', '2020', '2010', '2016', '2019', '2017', '2019', '2012', '2018', '2019', '2012', '2017', '2008', '2014', '2020', '2014', '2016', '2018', '2020', '2013', '2013', '2014', '2013', '2013', '2012', '2019', '2019', '2015', '2018', '2020', '2014', '2014', '2014', '2013', '1993', '2021', '2018', '2020', '1999', '2016', '2016', '2017', '1997', '2008', '2013', 'N/A', '2013', '2019', '2014', '2019', '1990', '2015', '2014', '2016', '2017', '2018', '2008', '2009', '1999', '2014', '2016', '2014', '2017', '2017', '2020', '2020', '2017', '2012', '2013', '2013', '2011', '2015', '2014', '2018', '2016', '2017', '2011', '2018', '2020', '2020', '2017', '2014', '2008', '2014', '2016', '2017', '2013', '1999', '2010', '2022', '2020', '2016', '2018', '2018', '2011', '2010', '2016', '2013', '2016', '2016', '2014', '2009', '2008', '2015', '2018', '2015', '2011', '2013', '2018', '2018', '2019', '2018', '2017', '2008', '2018', '2014', '2019', '2018', '2019', '2014', '2015', '2018', '2019', '1992', '1999', '2020', '2019', '2019', '2017', '2020', '2012', '2013', '2015', '2012', '2013', '2019', '2010', '2017', '2014', '2012', '2020', 'N/A', '2014', '2010', '2019', '2011', '2018', '2012', '1988', '2015', '2019', '2014', '2014', '2019', '2019', 'N/A', '2018', '2011', '2018', '2014', '2016', '2016', '2013', '2019', '2017', '2019', '2014', '2019', '2016', '2013', '2020', '2020', '2013', '2014', '2017', '2008', '2019', '2008', '2010', '2018', '2016', '2015', '1992', '2013', '2014', '2019', '2011', '2017', '2020', '2016', '2015', '2007', '2016', '2015', '2010', '2008', '2017', '2020', '2008', '2018', '2016', '2017', '2011', '2014', '1990', '2013', '2020', '2011', '2020', '2018', '2006', '1996', '2019', '2013', '2020', '2014', '2018', '2016', '2017', '2016', '2016', '2017', '2018', '2012', '2013', '2016', '2006', '2019', '2011', '2011', '1999', '1999', '2011', '2016', '2020', '2017', '2014', '2010', '2018', '2011', '1994', '2008', '2012', '2003', '2019', '2015', '2018', 'N/A', '1999', '2017', '2018', 'N/A', '2016', '2001', '2018', '1990', 'N/A', '1994', '1954', '2009', '2019', '2010', '2012', '2017', 'N/A', '2018', 'N/A', 'N/A', '1994', 'N/A', '2023']\n"
     ]
    }
   ],
   "source": [
    "#Printing Data along with their length\n",
    "print('Dataset Name:-\\nlen:',len(dataset_name),'\\nData:\\n',dataset_name,'\\n\\n','Dataset type:-\\nlen:',len(data_type),'\\nData:\\n',data_type,'\\n\\n','Task:-\\nlen:',len(task),'\\nData:\\n',task,'\\n\\n','Attribute type:-\\nlen:',len(attribute_type),'\\nData:\\n',attribute_type,'\\n\\n','Number of instances:-\\nlen:',len(no_of_instances),'\\nData:\\n',no_of_instances,'\\n\\n','Number of attribute:-\\nlen:',len(no_of_attribute),'\\nData:\\n',no_of_attribute,'\\n\\n','Year:-\\nlen:',len(year),'\\nData:\\n',year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84faec",
   "metadata": {},
   "source": [
    "## Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6511464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the driver\n",
    "dr=wd.Chrome(executable_path=driver_path, options=options)\n",
    "#Opening the website on automated brave browser\n",
    "dr.get('https://www.naukri.com/hr-recruiters-consultants ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd17de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the required data\n",
    "name=[]\n",
    "designation=[]\n",
    "company=[]\n",
    "skills=[]\n",
    "location=[]\n",
    "url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ae43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the required data\n",
    "try:#handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]'):\n",
    "        name.append(i.text)#Appending name\n",
    "except NoSuchElementException:\n",
    "    name.append('-')#Appending '-' if name is not found\n",
    "    \n",
    "try:#handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "        company.append(i.text)#Appending company\n",
    "except NoSuchElementException:\n",
    "    company.append('-')#Appending '-' if company is not found\n",
    "    \n",
    "try:#handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//ul[@class=\"tags has-description\"]'):\n",
    "        skills.append(i.text.replace('\\n',', '))#Appending skills\n",
    "except NoSuchElementException:\n",
    "    skills.append('-')#Appending '-' if skills are  not found\n",
    "    \n",
    "try:#handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]'):\n",
    "        location.append(i.text)#Appending location\n",
    "except NoSuchElementException:\n",
    "    location.append('-')#Appending '-' if location is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0a0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping URLs\n",
    "try:#Handling exceptions\n",
    "    for i in dr.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]'):\n",
    "        url.append(i.get_attribute('href'))#Appending URLs\n",
    "except NoSuchElementException:\n",
    "    print('Exception Raised...Unable to locate URLs')#Raising exception if URL is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84847b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating URLs\n",
    "try:#Handling exceptions\n",
    "    \n",
    "    for i in url:\n",
    "        dr.get(i)\n",
    "        try:#handling exceptions\n",
    "            designation.append(dr.find_element(By.XPATH,'//div[@class=\"details\"]/span/a').text)#Appending designation\n",
    "        except NoSuchElementException:\n",
    "            designation.append('-')#Appending '-' if designation is not found\n",
    "        \n",
    "        #Adding delay to allow the website to load and update the content\n",
    "        time.sleep(5)    \n",
    "        \n",
    "\n",
    "except InvalidArgumentException:\n",
    "    print('Exception raised...Invalid argument')#Raising exception if it encounters invalid argument\n",
    "except TimeoutException:\n",
    "    print('Exception Raised...Timeout error')#Raising exception if timeout error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a28f810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:-\n",
      "len: 20 \n",
      "Data:\n",
      " ['Hiring Freshers : HR Executive: Recruiter-Gurugram : ACS', 'Assistant Manager - HR (Field Level Recruitment)', 'HR Recruiter', 'Hiring For HR Recruiters', 'Work from Home Opportunity: MBA(HR) freshers with Team O3Hire', 'HR Intern', 'HR Executive || Nagpur || Third Party Payroll', 'HR Payroll Executive', 'HR Intern', 'Executive/ Assistant Manager HR Generalist - Pune ( Dress Code )', 'Opening For Management Trainee / Executive - HR', 'HR Recruiter - Talent Acquisition -', 'HR Recruiter', 'Hiring Freshers : HR Executive: Recruiter-Jaipur : ACS', 'Hiring For HR freshers / Day shift / Recruiter', 'Hiring For HR Recruiter || Fresher / EXP || Day Shift || Up To 25k TH', 'HR Recruiter', 'HR Recruiter', 'Huge Openings For HR Recruiter (Female)', 'Hiring For HR Associate | Off-Role | End-To-End Recruitment'] \n",
      "\n",
      " Designation:-\n",
      "len: 20 \n",
      "Data:\n",
      " ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'] \n",
      "\n",
      " Company:-\n",
      "len: 20 \n",
      "Data:\n",
      " ['Advance Career Solutions', 'Muthoot Microfin', 'Symphoni Hr', 'Ontrack Hr Services', 'O3 Hire', 'Lifecell', 'Tata AIA Life Insurance', 'Cedcoss Technologies', 'HR Remedy India', 'OASIS', 'Sahajanand Medical Technologies', 'Fashion Tv India', 'Dentistry Billing & Consulting', 'Advance Career Solutions', 'Black And White Business Solutions', 'Axis Services', 'Hands On', 'NMS Consultant', 'Hireworks Recruitment Consultants', 'Kotak Life Insurance'] \n",
      "\n",
      " Skills:-\n",
      "len: 20 \n",
      "Data:\n",
      " ['communication skills, Recruitment, Hiring, Acd, Ac, Hrsd', 'NBFC, recruitment, Mass Hiring, Bulk Hiring, Life cycle, Talent acquisition, Bulk, Telephonic', 'Recruitment, Exit formalities, Talent acquisition, Resource management, Mass recruitment, Joining formalities, Human resource management, Head hunting', 'recruitment skills, good communication, Hiring, Recruitment, End, End To End, Hrsd, End To End Recruitment', 'MBA, Sales, Mass, Hrsd, Bulk, Mass hiring, Talent acquisition, Acquisition', 'Recruitment, Recruitment Operations, Operations, Hrsd', 'Human Resource, Hiring, Talent Acquisition, Third party, Resource, Acquisition, Hrsd, Payroll', 'ESIC, Office, Microsoft, Health, Time management, Payroll software, Administration, Software', 'Human Resource, Hiring, Database management, Resource, DBMS, Hrsd, Recruitment, Management', 'hr generalist activities, HR Information System, HR Coordination, HR Administration, HR Strategy, Generalist Activities, Corporate, Management', 'Recruitment, Talent Acquisition, Training, MIS, Hrsd, Engagement, Acquisition, Management', 'Management, Hrsd, Licensing, Talent acquisition, Time management, Acquisition, Monitoring, Time Managements', 'Recruitment Management, HR assistance, Hiring, Recruitment, Assistance, Bulk, Hrsd, Bulk hiring', 'Recruitment, communication skills, Hrsd, Ac, Acd, Hiring', 'communication skills, Hiring, Lateral hiring, Resource management, Resource, Recruitment, Interpersonal skills, Interpersonal', 'BPO, hr, Talent Acquisition, fresher, recruitment, Chat Process, Resource management, Human resource management', 'recruitment, Mapping, Salary, Negotiation, Salary negotiation, End, End To End, Hrsd', 'Pharma Recruiter, IT Recruitment, Human Resource Management, Technical Recruitment, Back Office, Technical, Hiring, Recruitment', 'HR, HR Recruiter, Recruitment, Human Resource, Recruiter, Interpersonal skills, Job posting, Hiring', 'end to end recruitment, Screening Resumes, Coordination, Screening, Recruitment, End To End, Sourcing, Interview coordination'] \n",
      "\n",
      " Location:-\n",
      "len: 20 \n",
      "Data:\n",
      " ['Gurgaon/ Gurugram, Haryana', 'Bhubaneswar, Odisha, Hubli, Karnataka, Sambalpur, Odisha, Ambala, Haryana, Belagavi/ Belgaum, Karnataka', 'Remote', 'Coimbatore, Tamil Nadu', 'Haridwar, Uttarakhand, Dehradun, Uttarakhand, Roorkee, Uttarakhand, Haldwani, Uttarakhand, Almora, Uttarakhand, Rishikesh, Uttarakhand', 'Hybrid - Chennai', 'Nagpur, Maharashtra', 'Lucknow', 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Ahmedabad, Bangalore/Bengaluru, Delhi / NCR', 'Pune, Maharashtra(Koregaon Park)', 'Mumbai (All Areas)', 'Mumbai', 'Noida, Uttar Pradesh', 'Jaipur, Rajasthan', 'Bangalore/Bengaluru(Vijayanagar +2)', 'Hyderabad/Secunderabad', 'New Delhi(Uttam Nagar +6)', 'Indore', 'Hybrid - Chennai', 'Mumbai Suburban, Maharashtra, Goregaon, Maharashtra, Mumbai (All Areas)']\n"
     ]
    }
   ],
   "source": [
    "#Printing Data along with their length\n",
    "print('Name:-\\nlen:',len(name),'\\nData:\\n',name,'\\n\\n','Designation:-\\nlen:',len(designation),'\\nData:\\n',designation,'\\n\\n','Company:-\\nlen:',len(company),'\\nData:\\n',company,'\\n\\n','Skills:-\\nlen:',len(skills),'\\nData:\\n',skills,'\\n\\n','Location:-\\nlen:',len(location),'\\nData:\\n',location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed8753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
